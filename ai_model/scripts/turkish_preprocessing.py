"""
Turkish Text Preprocessing for Synthetic Data
============================================

Bu modÃ¼l, TÃ¼rkÃ§e metin verilerinin Ã¶n iÅŸlenmesi iÃ§in Zemberek kÃ¼tÃ¼phanesi
entegrasyonunu hazÄ±rlar. GÃ¼n 4 gÃ¶revleri kapsamÄ±nda detaylandÄ±rÄ±lacaktÄ±r.

Requirements:
    pip install zemberek-python

Usage:
    from ai_model.scripts.turkish_preprocessing import TurkishPreprocessor
    
    preprocessor = TurkishPreprocessor()
    normalized = preprocessor.normalize_text("Ä°nternetimin hÄ±zÄ±nÄ± yÃ¼kseltmek istiyorum.")
"""

try:
    from zemberek import TurkishMorphology  # type: ignore
    ZEMBEREK_AVAILABLE = True
except ImportError:
    ZEMBEREK_AVAILABLE = False
    print("âš ï¸  Zemberek kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. Kurulum iÃ§in: pip install zemberek-python")

import re
from typing import List, Dict, Optional


class TurkishPreprocessor:
    """TÃ¼rkÃ§e metin Ã¶n iÅŸleme sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        """Zemberek morphology analyzer'Ä± baÅŸlat"""
        if ZEMBEREK_AVAILABLE:
            try:
                self.morphology = TurkishMorphology.createWithDefaults()
                self.enabled = True
            except Exception as e:
                print(f"âš ï¸  Zemberek baÅŸlatÄ±lamadÄ±: {e}")
                self.enabled = False
        else:
            self.enabled = False
    
    def normalize_text(self, text: str) -> str:
        """
        TÃ¼rkÃ§e metni normalize et
        
        Args:
            text: Ä°ÅŸlenecek TÃ¼rkÃ§e metin
            
        Returns:
            Normalize edilmiÅŸ metin
        """
        if not text:
            return ""
        
        # Temel temizlik
        normalized = self._basic_cleanup(text)
        
        # Zemberek ile normalize etme (mevcut ise)
        if self.enabled:
            normalized = self._zemberek_normalize(normalized)
        else:
            # Fallback: Basit normalize etme
            normalized = self._simple_normalize(normalized)
        
        return normalized.strip()
    
    def extract_keywords(self, text: str) -> List[str]:
        """
        Metinden anahtar kelimeleri Ã§Ä±kar
        
        Args:
            text: Analiz edilecek metin
            
        Returns:
            Anahtar kelimeler listesi
        """
        if not self.enabled:
            return self._simple_keyword_extraction(text)
        
        keywords = []
        words = text.split()
        
        for word in words:
            # Zemberek ile kÃ¶k bulma
            analysis = self.morphology.analyzeSentence(word)
            if analysis:
                # Ä°lk analiz sonucunun kÃ¶kÃ¼nÃ¼ al
                root = analysis[0].getDictionaryItem().root
                keywords.append(root)
            else:
                keywords.append(word.lower())
        
        return list(set(keywords))  # TekrarlarÄ± kaldÄ±r
    
    def _basic_cleanup(self, text: str) -> str:
        """Temel metin temizliÄŸi"""
        # Fazla boÅŸluklarÄ± temizle
        text = re.sub(r'\s+', ' ', text)
        
        # Ã–zel karakterleri temizle (sadece gerekli olanlarÄ±)
        text = re.sub(r'[^\w\s\.\,\!\?\;]', '', text)
        
        return text
    
    def _zemberek_normalize(self, text: str) -> str:
        """Zemberek ile normalize etme"""
        try:
            # Zemberek normalization API kullan
            normalized = self.morphology.normalizeText(text)
            return normalized
        except Exception as e:
            print(f"âš ï¸  Zemberek normalization hatasÄ±: {e}")
            return self._simple_normalize(text)
    
    def _simple_normalize(self, text: str) -> str:
        """Basit normalize etme (Zemberek olmadan)"""
        # TÃ¼rkÃ§e karakter dÃ¶nÃ¼ÅŸÃ¼mleri
        replacements = {
            'Ä°': 'i', 'I': 'Ä±', 'Å': 'ÅŸ', 'Ä': 'ÄŸ', 
            'Ãœ': 'Ã¼', 'Ã–': 'Ã¶', 'Ã‡': 'Ã§'
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        return text.lower()
    
    def _simple_keyword_extraction(self, text: str) -> List[str]:
        """Basit anahtar kelime Ã§Ä±karma"""
        # TÃ¼rkÃ§e stop words (basit liste)
        stop_words = {
            've', 'ile', 'bu', 'ÅŸu', 'o', 'bir', 'iÃ§in', 'ki', 'da', 'de',
            'olan', 'olan', 'olarak', 'gibi', 'kadar', 'daha', 'en', 'Ã§ok',
            'az', 'var', 'yok', 'mÄ±', 'mi', 'mu', 'mÃ¼'
        }
        
        words = text.lower().split()
        keywords = [w for w in words if w not in stop_words and len(w) > 2]
        
        return list(set(keywords))


def preprocess_synthetic_data_inputs(data_points: List[Dict]) -> List[Dict]:
    """
    Sentetik veri setindeki input'larÄ± TÃ¼rkÃ§e Ã¶n iÅŸleme tabi tut
    
    Args:
        data_points: Sentetik veri noktalarÄ± listesi
        
    Returns:
        Ã–n iÅŸleme tabi tutulmuÅŸ veri noktalarÄ±
    """
    preprocessor = TurkishPreprocessor()
    
    processed_data = []
    
    for point in data_points:
        if 'input' in point:
            # Input metnini normalize et
            original_input = point['input']
            normalized_input = preprocessor.normalize_text(original_input)
            
            # Anahtar kelimeleri Ã§Ä±kar (opsiyonel metadata olarak)
            keywords = preprocessor.extract_keywords(original_input)
            
            # Yeni veri noktasÄ± oluÅŸtur
            processed_point = point.copy()
            processed_point['input'] = normalized_input
            processed_point['_metadata'] = {
                'original_input': original_input,
                'keywords': keywords,
                'preprocessed': True
            }
            
            processed_data.append(processed_point)
        else:
            processed_data.append(point)
    
    return processed_data


# Test fonksiyonu
if __name__ == "__main__":
    # Basit test
    preprocessor = TurkishPreprocessor()
    
    test_texts = [
        "Ä°nternetimin hÄ±zÄ±nÄ± yÃ¼kseltmek istiyorum.",
        "Fatura Ã¶deme durumunu kontrol etmek istiyorum.",
        "Åu anda hangi pakette olduÄŸumu Ã¶ÄŸrenmek istiyorum."
    ]
    
    print("ğŸ§ª TÃ¼rkÃ§e Ã–n Ä°ÅŸleme Testi")
    print("=" * 40)
    
    for text in test_texts:
        normalized = preprocessor.normalize_text(text)
        keywords = preprocessor.extract_keywords(text)
        
        print(f"ğŸ“ Orijinal: {text}")
        print(f"âœ¨ Normalize: {normalized}")
        print(f"ğŸ”‘ Anahtar Kelimeler: {keywords}")
        print("-" * 40) 