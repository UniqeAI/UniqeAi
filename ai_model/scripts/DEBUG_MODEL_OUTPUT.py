# -*- coding: utf-8 -*-
"""
ğŸ” DEBUG MODEL OUTPUT - Model Ã‡Ä±ktÄ±sÄ± Analizi
=============================================

Bu script, modelin ham Ã§Ä±ktÄ±sÄ±nÄ± analiz ederek hangi formatta
araÃ§ Ã§aÄŸrÄ±larÄ± yaptÄ±ÄŸÄ±nÄ± tespit eder.
"""

import os
import sys
from pathlib import Path
from rich.console import Console

# --- Proje KÃ¶k Dizini ---
try:
    PROJECT_ROOT = Path(__file__).resolve().parents[3]
except (NameError, IndexError):
    PROJECT_ROOT = Path.cwd()

GGUF_MODEL_DIR = PROJECT_ROOT / "UniqeAi/ai_model/gguf_model"

console = Console()

def find_latest_gguf_model(model_dir: Path):
    """En yeni GGUF modelini bulur"""
    if not model_dir.exists():
        return None
    gguf_files = list(model_dir.glob("*.gguf"))
    if not gguf_files:
        return None
    return max(gguf_files, key=lambda p: p.stat().st_mtime)

def debug_model_response():
    """Model yanÄ±tÄ±nÄ± debug eder"""
    
    try:
        from llama_cpp import Llama
    except ImportError:
        console.print("[bold red]HATA: llama-cpp-python kurulu deÄŸil.[/bold red]")
        return

    model_path = find_latest_gguf_model(GGUF_MODEL_DIR)
    if not model_path:
        console.print("[bold red]HATA: GGUF model bulunamadÄ±![/bold red]")
        return

    console.print(f"[yellow]ğŸ” Model yÃ¼kleniyor: {model_path.name}[/yellow]")

    llm = Llama(
        model_path=str(model_path),
        n_ctx=4096,
        n_gpu_layers=-1,
        n_threads=os.cpu_count() - 1 if os.cpu_count() and os.cpu_count() > 1 else 1,
        verbose=False,
        chat_format="llama-3"
    )

    # Test mesajlarÄ±
    test_cases = [
        {
            "name": "Basit Fatura Sorgusu",
            "input": "FaturamÄ± gÃ¶rmek istiyorum"
        },
        {
            "name": "Veri Seti TarzÄ± KarmaÅŸÄ±k",
            "input": "Babam geÃ§en ay vefat etti. Onun telefonunu ve internet aboneliÄŸini kapatmak istiyorum ama Ã§ok zor geliyor. Bu sÃ¼reÃ§te bana nasÄ±l yardÄ±mcÄ± olabilirsiniz?"
        }
    ]

    system_prompt = """Sen, UniqeAi tarafÄ±ndan geliÅŸtirilmiÅŸ uzman bir Telekom MÃ¼ÅŸteri Hizmetleri AsistanÄ±sÄ±n. 

KullanabileceÄŸin araÃ§lar:
- get_current_bill: GÃ¼ncel fatura bilgilerini getirir
- get_customer_profile: MÃ¼ÅŸteri profil bilgilerini getirir  
- pay_bill: Fatura Ã¶deme iÅŸlemi yapar

Bir aracÄ± kullanman gerektiÄŸinde, ÅŸu formatlardan birini kullan:
1. <|begin_of_tool_code|>print(fonksiyon_adi(parametre=deger))<|end_of_tool_code|>
2. arac_cagrilari: [{"fonksiyon": "fonksiyon_adi", "parametreler": {"parametre": "deger"}}]

Her iki formatÄ± da dene ve hangi birini tercih ettiÄŸini gÃ¶ster."""

    for test_case in test_cases:
        console.print(f"\n{'='*60}")
        console.print(f"ğŸ§ª [bold blue]Test: {test_case['name']}[/bold blue]")
        console.print(f"{'='*60}")
        
        console.print(f"ğŸ‘¤ [bold blue]KullanÄ±cÄ±:[/bold blue] {test_case['input']}")
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": test_case['input']}
        ]
        
        console.print("[yellow]... model dÃ¼ÅŸÃ¼nÃ¼yor ...[/yellow]")
        
        response = llm.create_chat_completion(
            messages=messages,
            temperature=0.2,
            stop=["<|eot_id|>"],
        )
        
        raw_response = response['choices'][0]['message']['content']
        
        console.print(f"\nğŸ¤– [bold green]Model (HAM Ã‡IKTI):[/bold green]")
        console.print(f"[cyan]{raw_response}[/cyan]")
        
        # Format analizi
        console.print(f"\nğŸ” [bold yellow]FORMAT ANALÄ°ZÄ°:[/bold yellow]")
        
        if "<|begin_of_tool_code|>" in raw_response:
            console.print("âœ… Ä°ngilizce tool code formatÄ± BULUNDU")
        else:
            console.print("âŒ Ä°ngilizce tool code formatÄ± bulunamadÄ±")
            
        if "arac_cagrilari" in raw_response:
            console.print("âœ… TÃ¼rkÃ§e araÃ§ Ã§aÄŸrÄ±sÄ± formatÄ± BULUNDU")
        else:
            console.print("âŒ TÃ¼rkÃ§e araÃ§ Ã§aÄŸrÄ±sÄ± formatÄ± bulunamadÄ±")
            
        if "print(" in raw_response:
            console.print("âœ… Print formatÄ± BULUNDU")
        else:
            console.print("âŒ Print formatÄ± bulunamadÄ±")

        console.print(f"\nğŸ“Š [bold magenta]SONUÃ‡:[/bold magenta]")
        if "<|begin_of_tool_code|>" in raw_response or "arac_cagrilari" in raw_response:
            console.print("ğŸ¯ Model araÃ§ Ã§aÄŸrÄ±sÄ± yapmaya Ã§alÄ±ÅŸÄ±yor!")
        else:
            console.print("âš ï¸ Model araÃ§ Ã§aÄŸrÄ±sÄ± yapmÄ±yor - sadece metin yanÄ±t veriyor")

if __name__ == "__main__":
    console.print("\nğŸ” [bold green]DEBUG MODEL OUTPUT - Model Format Analizi[/bold green]")
    console.print("="*60)
    debug_model_response()