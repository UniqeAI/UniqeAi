#!/usr/bin/env python3
"""
ğŸ” Model Analysis - Model'in ne Ã¶ÄŸrendiÄŸini detaylÄ± analiz eder
============================================================

Model'in API pattern'larÄ±nÄ± ne kadar Ã¶ÄŸrendiÄŸini test eder.
"""

import torch
import warnings
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
from peft import PeftModel

warnings.filterwarnings("ignore")

class ModelAnalyzer:
    def __init__(self):
        self.model_path = "./qlora_fine_tuned_model"
        self.base_model_name = "meta-llama/Meta-Llama-3-8B-Instruct"
        self.model = None
        self.tokenizer = None
        
    def load_model(self):
        """Load model for analysis"""
        print("ğŸ” Model analiz iÃ§in yÃ¼kleniyor...")
        
        try:
            bnb_config = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_use_double_quant=True,
                bnb_4bit_quant_type="nf4",
                bnb_4bit_compute_dtype=torch.bfloat16
            )
            
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.base_model_name,
                trust_remote_code=True
            )
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            base_model = AutoModelForCausalLM.from_pretrained(
                self.base_model_name,
                quantization_config=bnb_config,
                device_map="auto",
                torch_dtype=torch.float16,
                trust_remote_code=True,
                offload_buffers=True
            )
            
            self.model = PeftModel.from_pretrained(
                base_model,
                self.model_path,
                device_map="auto"
            )
            
            print("âœ… Model yÃ¼klendi")
            return True
            
        except Exception as e:
            print(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
            return False
    
    def test_api_understanding(self):
        """Test if model understands API patterns"""
        print("\nğŸ§ª API Pattern Analizi")
        print("=" * 50)
        
        # Dataset'teki gerÃ§ek API'ler
        correct_apis = [
            "get_current_bill",
            "update_customer_contact", 
            "create_fault_ticket",
            "test_internet_speed",
            "enable_roaming",
            "change_package",
            "get_customer_profile",
            "suspend_line",
            "reactivate_line"
        ]
        
        test_prompts = [
            "FaturamÄ± gÃ¶rmek istiyorum",
            "Telefon numaramÄ± deÄŸiÅŸtirmek istiyorum", 
            "ArÄ±za kaydÄ± oluÅŸturmak istiyorum",
            "Ä°nternet hÄ±zÄ±mÄ± test etmek istiyorum",
            "Roaming aÃ§mak istiyorum",
            "Paketimi deÄŸiÅŸtirmek istiyorum",
            "Profil bilgilerimi gÃ¶rmek istiyorum",
            "HattÄ±mÄ± dondurmak istiyorum",
            "HattÄ±mÄ± aktive etmek istiyorum"
        ]
        
        results = []
        
        for i, prompt in enumerate(test_prompts):
            print(f"\nğŸ”¸ Test {i+1}: {prompt}")
            
            # Generate response
            response = self.generate_simple(prompt)
            print(f"Model: {response}")
            
            # Check for correct API
            expected_api = correct_apis[i]
            has_correct_api = expected_api in response
            has_tool_wrapper = "<tool_code>" in response
            has_backend_prefix = "backend_api." in response
            
            print(f"  âœ“ Tool wrapper: {'âœ…' if has_tool_wrapper else 'âŒ'}")
            print(f"  âœ“ Backend prefix: {'âœ…' if has_backend_prefix else 'âŒ'}")
            print(f"  âœ“ Correct API ({expected_api}): {'âœ…' if has_correct_api else 'âŒ'}")
            
            results.append({
                'prompt': prompt,
                'response': response,
                'has_wrapper': has_tool_wrapper,
                'has_prefix': has_backend_prefix,
                'has_correct_api': has_correct_api,
                'expected_api': expected_api
            })
        
        return results
    
    def analyze_results(self, results):
        """Analyze test results"""
        print("\nğŸ“Š SONUÃ‡ ANALÄ°ZÄ°")
        print("=" * 50)
        
        total = len(results)
        wrapper_correct = sum(1 for r in results if r['has_wrapper'])
        prefix_correct = sum(1 for r in results if r['has_prefix'])
        api_correct = sum(1 for r in results if r['has_correct_api'])
        
        print(f"ğŸ“‹ Test edilen senaryo: {total}")
        print(f"ğŸ”§ Tool wrapper (<tool_code>): {wrapper_correct}/{total} ({wrapper_correct/total*100:.1f}%)")
        print(f"ğŸ”Œ Backend prefix (backend_api.): {prefix_correct}/{total} ({prefix_correct/total*100:.1f}%)")
        print(f"ğŸ¯ DoÄŸru API: {api_correct}/{total} ({api_correct/total*100:.1f}%)")
        
        print(f"\nğŸ’¡ DEÄERLENDIRME:")
        if wrapper_correct >= total * 0.8:
            print("âœ… Model tool format'Ä±nÄ± Ã¶ÄŸrenmiÅŸ")
        else:
            print("âŒ Model tool format'Ä±nÄ± Ã¶ÄŸrenememiÅŸ")
            
        if prefix_correct >= total * 0.8:
            print("âœ… Model backend_api prefix'ini Ã¶ÄŸrenmiÅŸ")
        else:
            print("âŒ Model backend_api prefix'ini Ã¶ÄŸrenememiÅŸ")
            
        if api_correct >= total * 0.5:
            print("ğŸŸ¡ Model API'leri kÄ±smen Ã¶ÄŸrenmiÅŸ")
        elif api_correct >= total * 0.2:
            print("âš ï¸ Model API'leri Ã§ok az Ã¶ÄŸrenmiÅŸ")
        else:
            print("âŒ Model API'leri hiÃ§ Ã¶ÄŸrenememiÅŸ")
        
        # Recommendation
        print(f"\nğŸ¯ Ã–NERÄ°:")
        if api_correct < total * 0.3:
            print("ğŸ”„ FULL RETRAIN Ã¶neriliyor - Model temelden yeniden eÄŸitilmeli")
            print("   - Learning rate dÃ¼ÅŸÃ¼rÃ¼lmeli")
            print("   - Epoch sayÄ±sÄ± artÄ±rÄ±lmalÄ±") 
            print("   - Dataset quality kontrol edilmeli")
        elif api_correct < total * 0.7:
            print("ğŸ”§ TARGETED FIX Ã¶neriliyor - Belirli API'ler iÃ§in ek eÄŸitim")
        else:
            print("âœ¨ Model iyi durumda - KÃ¼Ã§Ã¼k iyileÅŸtirmeler yeterli")
            
        return {
            'wrapper_rate': wrapper_correct/total,
            'prefix_rate': prefix_correct/total,
            'api_rate': api_correct/total
        }
    
    def generate_simple(self, prompt):
        """Simple generation for testing"""
        if not self.model:
            return "Model yÃ¼klÃ¼ deÄŸil"
            
        formatted_prompt = f"### Instruction:\n{prompt[:20].title()}\n\n### Input:\n{prompt}\n\n### Response:\n"
        
        try:
            inputs = self.tokenizer(
                formatted_prompt,
                return_tensors="pt",
                max_length=512,
                truncation=True
            )
            
            if torch.cuda.is_available():
                inputs = {k: v.to("cuda:0") for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=60,
                    temperature=0.1,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    use_cache=False
                )
            
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            response = response.split("### Response:\n")[-1].strip()
            response = response.replace("<|endoftext|>", "")
            response = response.split("### Instruction:")[0].strip()
            
            return response
            
        except Exception as e:
            return f"Hata: {e}"

def main():
    analyzer = ModelAnalyzer()
    
    if not analyzer.load_model():
        return
    
    # Test API understanding
    results = analyzer.test_api_understanding()
    
    # Analyze results
    scores = analyzer.analyze_results(results)
    
    # Summary
    print(f"\nğŸ† Ã–ZET SKOR:")
    print(f"Format: {scores['wrapper_rate']*100:.1f}%")
    print(f"Prefix: {scores['prefix_rate']*100:.1f}%") 
    print(f"API DoÄŸruluk: {scores['api_rate']*100:.1f}%")

if __name__ == "__main__":
    main() 