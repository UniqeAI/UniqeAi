"""
ğŸš€ SUPREME HUMAN-LEVEL DATASET GENERATOR V3 - MODULAR EDITION
=============================================================

Bu modÃ¼l, SupremeHumanLevelDatasetGenerator'Ä±n ana sÄ±nÄ±fÄ±nÄ± iÃ§erir.
ModÃ¼ler yapÄ±da organize edilmiÅŸ, tÃ¼m bileÅŸenleri bir araya getirir.
"""

import json
import random
import uuid
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path
from .models import CulturalContext, PersonalityProfile

# ModÃ¼ler importlar
from .models import ScenarioType, CognitiveState, EmotionalContext
from .exceptions import DataGenerationError, ValidationError
from .validators import (
    validate_scenario_quality,
    verify_pydantic_compliance
)
from .utils import generate_user_id, generate_mock_data_for_model
from .config import (
    PROJECT_ROOT,
    DEFAULT_OUTPUT_DIR,
    SCENARIO_WEIGHTS,
    API_RESPONSE_MAPPING
)
from .generators import (
    generate_standard_scenario,
    generate_tool_chaining_scenario,
    generate_proactive_scenario,
    generate_disambiguation_scenario,
    generate_multi_intent_scenario,
    generate_ethical_dilemma_scenario,
    generate_negotiation_skills_scenario,
    generate_teaching_mentoring_scenario,
    generate_innovation_thinking_scenario,
    generate_temporal_reasoning_scenario,
    generate_cross_cultural_communication_scenario,
    generate_advanced_error_recovery_scenario,
    generate_social_dynamics_scenario,
    generate_conflicting_information_scenario,
    generate_strategic_planning_scenario,
    generate_empathetic_reasoning_scenario,
    generate_adaptive_communication_scenario,
    generate_predictive_analytics_scenario,
    generate_resource_optimization_scenario,
    generate_collaborative_filtering_scenario,
    generate_payment_history_scenario,
    generate_setup_autopay_scenario,
    generate_change_package_scenario,
    generate_suspend_line_scenario,
    generate_error_response_scenario,
    generate_package_details_scenario,
    generate_enable_roaming_scenario,
    generate_get_user_tickets_scenario,
    generate_get_ticket_status_scenario,
    generate_test_internet_speed_scenario
)

# Lazy loading ve initialize metodlarÄ± iÃ§in import
from .lazy_loading import (
    personality_profiles_property,
    cognitive_patterns_property,
    meta_templates_property,
    cultural_contexts_property,
    temporal_reasoning_patterns_property,
    innovation_frameworks_property
)

from .initializers import (
    initialize_enhanced_personality_profiles,
    initialize_advanced_cognitive_patterns,
    initialize_comprehensive_meta_templates,
    initialize_cultural_contexts,
    initialize_temporal_patterns,
    initialize_innovation_frameworks
)

class SupremeHumanLevelDatasetGenerator:
    """
    ğŸš€ SUPREME V3 - SÄ±fÄ±r ToleranslÄ± Dataset Generator
    
    Bu sÄ±nÄ±f, %100 Pydantic uyumlu, sÄ±fÄ±r toleranslÄ±,
    enterprise seviyesinde kalitede veri Ã¼retir.
    """
    
    def __init__(self):
        print("ğŸš€ SUPREME V3 - SÄ±fÄ±r ToleranslÄ± Dataset Generator baÅŸlatÄ±lÄ±yor...")
        print("âœ… %100 Pydantic Validasyon ZorunluluÄŸu")
        print("âœ… telekom_api_schema.py Mutlak Uyumluluk")
        print("âœ… SÄ±fÄ±r Hata ToleransÄ±")
        
        # API Fonksiyon -> Response Model eÅŸleÅŸtirmesi (KRÄ°TÄ°K)
        self.api_response_map = self._build_api_response_mapping()
        
        # Kalite kontrol sayaÃ§larÄ±
        self.validation_errors = 0
        self.schema_violations = 0 
        print("âœ… Uzman Seviyesi Optimizasyonlar (Memory Optimized)")
        
        # Lazy loading iÃ§in cache'ler - memory optimization
        self._personality_profiles_cache = None
        self._cognitive_patterns_cache = None
        self._meta_templates_cache = None
        self._cultural_contexts_cache = None
        self._temporal_patterns_cache = None
        self._innovation_frameworks_cache = None
        
        # Statistics tracking
        self.generated_scenarios = {scenario.value: 0 for scenario in ScenarioType}
        self.total_generated = 0
        
        print(f"ğŸ“Š {len(self.api_response_map)} API fonksiyonu eÅŸleÅŸtirildi")

    def _build_api_response_mapping(self) -> Dict[str, Any]:
        """
        KRÄ°TÄ°K FONKSÄ°YON: API fonksiyonlarÄ±nÄ± response modellerine eÅŸleÅŸtirir.
        Bu, %100 ÅŸema uyumluluÄŸu iÃ§in hayati Ã¶nem taÅŸÄ±r.
        """
        return API_RESPONSE_MAPPING

    def _generate_mock_data_for_model(self, model_class) -> Dict[str, Any]:
        """
        Model sÄ±nÄ±fÄ± iÃ§in mock data Ã¼retir
        """
        return generate_mock_data_for_model(model_class)

    def _create_validated_response(self, model_class, override_data: Optional[Dict] = None) -> str:
        """
        SUPREME V3 + ENTERPRISE SCHEMA INTEGRATION - %100 PYDANTÄ°C DOÄRULAMA GÃœVENCESÄ°
        
        Yeni telekom_api_schema v3.0-SUPREME utility fonksiyonlarÄ±nÄ± kullanarak
        enterprise-grade mock response oluÅŸturur.
        
        ğŸš€ YENÄ° Ã–ZELLÄ°KLER v3.0:
        - Schema v3.0 entegrasyonu
        - Enterprise-grade mock data generation
        - GeliÅŸmiÅŸ validation with detailed error reporting
        - 100% schema compliance guarantee
        """
        try:
            # Schema v3.0 ile geliÅŸmiÅŸ mock data Ã¼retimi
            mock_data = self._generate_mock_data_for_model(model_class)
            if override_data:
                for key, value in override_data.items():
                    # usage_percentage iÃ§in Ã¶zel kontrol
                    if key == "usage_percentage" and isinstance(value, dict):
                        # Her deÄŸerin 100'den kÃ¼Ã§Ã¼k olduÄŸundan emin ol
                        fixed_usage = {}
                        for usage_key, usage_value in value.items():
                            if isinstance(usage_value, int) and usage_value > 100:
                                fixed_usage[usage_key] = random.randint(0, 100)
                                print(f"ğŸ”§ Usage percentage dÃ¼zeltildi: {usage_key}: {usage_value} â†’ {fixed_usage[usage_key]}")
                            else:
                                fixed_usage[usage_key] = usage_value
                        mock_data[key] = fixed_usage
                    else:
                        mock_data[key] = value
            
            # Enterprise-grade Pydantic doÄŸrulama
            validated = model_class(**mock_data)
            
            # JSON serileÅŸtirme kontrolÃ¼
            json_result = validated.model_dump_json(indent=None)
            
            # JSON'Ä±n parse edilebilir olduÄŸunu kontrol et
            json.loads(json_result)
            
            return json_result
            
        except ValidationError as e:
            print(f"âŒ KRÄ°TÄ°K HATA - Pydantic Validation: {model_class.__name__}")
            print(f"   HatalÄ± veri: {mock_data}")
            print(f"   Hata detayÄ±: {e}")
            raise ValueError(f"API ÅŸemasÄ± uyumsuzluÄŸu: {model_class.__name__} - {e}")
        except json.JSONDecodeError as e:
            print(f"âŒ KRÄ°TÄ°K HATA - JSON Serialization: {model_class.__name__}")
            print(f"   JSON hatasÄ±: {e}")
            raise ValueError(f"JSON serileÅŸtirme hatasÄ±: {model_class.__name__}")
        except Exception as e:
            print(f"âŒ KRÄ°TÄ°K HATA - Beklenmeyen: {model_class.__name__}")
            print(f"   Hata: {e}")
            raise

    def _get_scenario_generators(self) -> Dict[str, callable]:
        """
        Senaryo Ã¼reticilerini dÃ¶ndÃ¼rÃ¼r
                    # Yeni entegre edilen temel senaryolar
            ScenarioType.STANDARD.value: generate_standard_scenario,
            ScenarioType.TOOL_CHAINING.value: generate_tool_chaining_scenario,
            ScenarioType.PROACTIVE.value: generate_proactive_scenario,
            ScenarioType.DISAMBIGUATION.value: generate_disambiguation_scenario,
            ScenarioType.MULTI_INTENT.value: generate_multi_intent_scenario,
            ScenarioType.ETHICAL_DILEMMA.value: generate_ethical_dilemma_scenario,
            
            # Mevcut geliÅŸmiÅŸ senaryolar
            ScenarioType.NEGOTIATION_SKILLS.value: generate_negotiation_skills_scenario,
            ScenarioType.TEACHING_MENTORING.value: generate_teaching_mentoring_scenario,
            ScenarioType.INNOVATION_THINKING.value: generate_innovation_thinking_scenario,
            ScenarioType.TEMPORAL_REASONING.value: generate_temporal_reasoning_scenario,
            ScenarioType.CROSS_CULTURAL_COMMUNICATION.value: generate_cross_cultural_communication_scenario,
            ScenarioType.ADVANCED_ERROR_RECOVERY.value: generate_advanced_error_recovery_scenario,
            ScenarioType.SOCIAL_DYNAMICS.value: generate_social_dynamics_scenario,
            ScenarioType.CONFLICTING_INFORMATION.value: generate_conflicting_information_scenario,
            ScenarioType.STRATEGIC_PLANNING.value: generate_strategic_planning_scenario,
            ScenarioType.EMPATHETIC_REASONING.value: generate_empathetic_reasoning_scenario,
            ScenarioType.ADAPTIVE_COMMUNICATION.value: generate_adaptive_communication_scenario,
            ScenarioType.PREDICTIVE_ANALYTICS.value: generate_predictive_analytics_scenario,
            ScenarioType.RESOURCE_OPTIMIZATION.value: generate_resource_optimization_scenario,
            ScenarioType.COLLABORATIVE_FILTERING.value: generate_collaborative_filtering_scenario,

            # --- UZMAN SEVÄ°YE EKLEME: EKSÄ°K API'LERÄ°N ENTEGRASYONU ---
            ScenarioType.PAYMENT_HISTORY.value: generate_payment_history_scenario,
            ScenarioType.SETUP_AUTOPAY.value: generate_setup_autopay_scenario,
            ScenarioType.CHANGE_PACKAGE.value: generate_change_package_scenario,
            ScenarioType.SUSPEND_LINE.value: generate_suspend_line_scenario,
            ScenarioType.ERROR_RESPONSE.value: generate_error_response_scenario,
            ScenarioType.PACKAGE_DETAILS.value: generate_package_details_scenario,
            ScenarioType.ENABLE_ROAMING.value: generate_enable_roaming_scenario,
            ScenarioType.GET_USER_TICKETS.value: generate_get_user_tickets_scenario,
            ScenarioType.GET_TICKET_STATUS.value: generate_get_ticket_status_scenario,
            ScenarioType.TEST_INTERNET_SPEED.value: generate_test_internet_speed_scenario,
  
        """
        return {
            #ScenarioType.ADAPTIVE_COMMUNICATION.value: generate_adaptive_communication_scenario,
            ScenarioType.COLLABORATIVE_FILTERING.value: generate_collaborative_filtering_scenario,

        }

    # ==============================================================================
    # ğŸš€ MEMORY OPTIMIZED LAZY PROPERTIES - V3 ENHANCEMENT
    # ==============================================================================
    
    @property
    def personality_profiles(self) -> Dict[str, 'PersonalityProfile']:
        """Lazy loading personality profiles - memory optimization"""
        return personality_profiles_property(self)
    
    @property
    def cognitive_patterns(self) -> Dict[str, List[str]]:
        """Lazy loading cognitive patterns - memory optimization"""
        return cognitive_patterns_property(self)
    
    @property
    def meta_templates(self) -> Dict[str, List[str]]:
        """Lazy loading meta templates - memory optimization"""
        return meta_templates_property(self)
    
    @property
    def cultural_contexts(self) -> Dict[str, 'CulturalContext']:
        """Lazy loading cultural contexts - memory optimization"""
        return cultural_contexts_property(self)
    
    @property
    def temporal_reasoning_patterns(self) -> Dict[str, List[str]]:
        """Lazy loading temporal patterns - memory optimization"""
        return temporal_reasoning_patterns_property(self)
    
    @property
    def innovation_frameworks(self) -> Dict[str, List[str]]:
        """Lazy loading innovation frameworks - memory optimization"""
        return innovation_frameworks_property(self)

    def generate_supreme_dataset(self, num_samples: int = 100) -> List[Dict[str, Any]]:
        """
        SUPREME VERSÄ°YON: %100 ÅŸema uyumlu, sÄ±fÄ±r toleranslÄ± dataset Ã¼retimi
        
        Bu fonksiyon, her Ã¼retilen verinin mÃ¼kemmel olmasÄ±nÄ± garanti eder.
        """
        
        print(f"ğŸš€ {num_samples} adet SUPREME seviye veri Ã¼retiliyor...")
        print("âœ… %100 Pydantic validasyon ZORUNLU")
        print("âœ… telekom_api_schema.py'ye MUTLAK uyumluluk")
        print("âœ… SÄ±fÄ±r tolerans politikasÄ± AKTÄ°F")
        
        dataset = []
        
        # Senaryo Ã¼reticilerini al
        scenario_generators = self._get_scenario_generators()
        
        # UZMAN SEVÄ°YESÄ° Ä°YÄ°LEÅTÄ°RME: TÃ¼m senaryo da artÄ±k burada tanÄ±mlÄ±
        scenario_types = list(scenario_generators.keys())
        
        # Her senaryo iÃ§in aÄŸÄ±rlÄ±klarÄ±n tam olarak eÅŸleÅŸtiÄŸinden emin ol
        weights = [SCENARIO_WEIGHTS.get(scenario_type, 1.0) for scenario_type in scenario_types]

        # UZMAN SEVÄ°YESÄ° KONTROL: AÄŸÄ±rlÄ±k ve metod listelerinin uzunluklarÄ± eÅŸleÅŸmelidir.
        if len(scenario_types) != len(weights):
            raise ValueError(
                f"Senaryo metodlarÄ± ({len(scenario_types)}) ve aÄŸÄ±rlÄ±klar ({len(weights)}) "
                "listelerinin uzunluklarÄ± eÅŸleÅŸmiyor. LÃ¼tfen kontrol edin."
            )


        # UZMAN SEVÄ°YE KALÄ°TE KONTROL DEÄÄ°ÅKENLERÄ°
        validation_errors = 0
        skipped_scenarios = 0
        pydantic_validations = 0

        # YENÄ° MANTIK: TÃ¼m senaryolarÄ± Ã¶nce topla, sonra istenilen miktarda Ã¼ret
        all_available_scenarios = []
        
        # Her senaryo tÃ¼rÃ¼ iÃ§in tÃ¼m senaryolarÄ± topla
        for scenario_type in scenario_types:
            try:
                scenarios = scenario_generators[scenario_type]()
                if isinstance(scenarios, list):
                    # EÄŸer liste dÃ¶ndÃ¼rÃ¼yorsa (yeni mantÄ±k)
                    all_available_scenarios.extend(scenarios)
                    print(f"ğŸ“¦ {scenario_type}: {len(scenarios)} senaryo eklendi")
                else:
                    # EÄŸer tek senaryo dÃ¶ndÃ¼rÃ¼yorsa (eski mantÄ±k - geriye uyumluluk)
                    all_available_scenarios.append(scenarios)
                    print(f"ğŸ“¦ {scenario_type}: 1 senaryo eklendi")
            except Exception as e:
                import traceback
                print(f"âŒ {scenario_type} senaryolarÄ± alÄ±nÄ±rken KRÄ°TÄ°K HATA:")
                print(f"   Hata tÃ¼rÃ¼: {type(e).__name__}")
                print(f"   Hata mesajÄ±: {str(e)}")
                print(f"   Tam traceback:")
                traceback.print_exc()
                print(f"   Senaryo tÃ¼rÃ¼: {scenario_type}")
                print(f"   Generator fonksiyonu: {scenario_generators[scenario_type].__name__}")
                continue
        
        print(f"ğŸ¯ Toplam {len(all_available_scenarios)} senaryo hazÄ±rlandÄ±")
        
        if not all_available_scenarios:
            raise ValueError("âŒ HiÃ§bir senaryo bulunamadÄ±!")
        
        # Ä°stenilen miktarda senaryo Ã¼ret
        for i in range(num_samples):
            # Mevcut senaryolardan rastgele seÃ§
            selected_scenario = random.choice(all_available_scenarios).copy()
            
            # Her senaryo iÃ§in benzersiz ID oluÅŸtur
            selected_scenario["id"] = f"{selected_scenario.get('id', 'scenario')}_{uuid.uuid4().hex[:8]}"
            
            try:
                # UZMAN SEVÄ°YE KALÄ°TE KONTROL: Her senaryo iÃ§in detaylÄ± doÄŸrulama
                validation_result = validate_scenario_quality(selected_scenario)
                if not validation_result["valid"]:
                    print(f"âš ï¸ Kalite kontrolÃ¼ baÅŸarÄ±sÄ±z: {selected_scenario.get('scenario_type', 'unknown')} - {validation_result['error']}")
                    validation_errors += 1
                    continue
                
                # UZMAN SEVÄ°YE KALÄ°TE KONTROL: API yanÄ±tlarÄ±nÄ±n Pydantic uyumluluÄŸunu kontrol et
                pydantic_check = verify_pydantic_compliance(selected_scenario)
                if not pydantic_check["valid"]:
                    print(f"âŒ Pydantic uyumsuzluÄŸu: {selected_scenario.get('scenario_type', 'unknown')} - {pydantic_check['error']}")
                    validation_errors += 1
                    continue
                
                pydantic_validations += pydantic_check["validated_count"]
                dataset.append(selected_scenario)
                
                scenario_type = selected_scenario.get('scenario_type', 'unknown')
                self.generated_scenarios[scenario_type] += 1
                self.total_generated += 1
                
                if (i + 1) % 10 == 0:
                    print(f"ğŸ“Š Ä°lerleme: {i + 1}/{num_samples} (%{(i+1)/num_samples*100:.1f}) - âœ… {pydantic_validations} Pydantic doÄŸrulama")
                    
            except ValidationError as e:
                print(f"âŒ Pydantic validasyon hatasÄ±: {e}")
                validation_errors += 1
                continue
            except Exception as e:
                import traceback
                print(f"âŒ Beklenmeyen hata: {e}")
                print(f"ğŸ” Hata tÃ¼rÃ¼: {type(e).__name__}")
                print(f"ğŸ” Senaryo tÃ¼rÃ¼: {selected_scenario.get('scenario_type', 'unknown')}")
                print(f"ğŸ” DetaylÄ± traceback:")
                traceback.print_exc()
                print("="*50)
                skipped_scenarios += 1
                continue
        
        print("\nğŸŠ DATASET GENERATÄ°ON TAMAMLANDI!")
        print("="*60)
        print("ğŸ“Š UZMAN SEVÄ°YE KALÄ°TE RAPORU:")
        print(f"   âœ… BaÅŸarÄ±lÄ± senaryolar: {len(dataset)}")
        print(f"   âŒ DoÄŸrulama hatalarÄ±: {validation_errors}")
        print(f"   âš ï¸ Atlanan senaryolar: {skipped_scenarios}")
        print(f"   ğŸ” Toplam Pydantic doÄŸrulama: {pydantic_validations}")
        print(f"   ğŸ“ˆ BaÅŸarÄ± oranÄ±: %{len(dataset)/(len(dataset)+validation_errors+skipped_scenarios)*100:.1f}")
        
        print("\nğŸ“Š Senaryo DaÄŸÄ±lÄ±mÄ±:")
        for scenario_type, count in self.generated_scenarios.items():
            if count > 0:
                print(f"   â€¢ {scenario_type}: {count} adet")
        
        # SUPREME V3: DETAYLI HATA ANALÄ°ZÄ° VE UYARI SÄ°STEMÄ°
        total_attempts = len(dataset) + validation_errors + skipped_scenarios
        error_rate = (validation_errors + skipped_scenarios) / total_attempts * 100 if total_attempts > 0 else 0
        
        if error_rate > 10:  # %10'dan fazla hata
            print(f"\nâš ï¸ YÃœKSEKRÄ°SK UYARI: Hata oranÄ± %{error_rate:.1f}")
            print(f"   â€¢ Validasyon hatalarÄ±: {validation_errors}")
            print(f"   â€¢ Atlanan senaryolar: {skipped_scenarios}")
            print(f"   â€¢ Toplam deneme: {total_attempts}")
            print("   ğŸ” Ã–NERÄ°LER:")
            print("     - telekom_api_schema.py uyumluluÄŸunu kontrol edin")
            print("     - _create_validated_response fonksiyonunu inceleyin")
            print("     - Pydantic model tanÄ±mlarÄ±nÄ± doÄŸrulayÄ±n")
        
        if len(dataset) == 0:
            error_msg = "âŒ KRÄ°TÄ°K BAÅARISIZLIK: HiÃ§bir geÃ§erli senaryo Ã¼retilemedi!"
            if validation_errors > 0:
                error_msg += f"\n   â€¢ {validation_errors} validasyon hatasÄ± oluÅŸtu"
            if skipped_scenarios > 0:
                error_msg += f"\n   â€¢ {skipped_scenarios} senaryo atlandÄ±"
            error_msg += "\n   ğŸš¨ Ã‡Ã–ZÃœM: LÃ¼tfen API ÅŸemasÄ± ve Pydantic tanÄ±mlarÄ±nÄ± kontrol edin"
            raise ValueError(error_msg)
        
        if error_rate > 25:  # %25'ten fazla hata kritik seviyede
            print(f"\nğŸš¨ KRÄ°TÄ°K UYARI: Ã‡ok yÃ¼ksek hata oranÄ± (%{error_rate:.1f})")
            print("   Bu dataset ile eÄŸitim Ã–NERÄ°LMEZ!")
            print("   LÃ¼tfen hatalarÄ± dÃ¼zelttikten sonra tekrar deneyin.")
        
        return dataset

    def save_dataset(self, dataset: List[Dict[str, Any]], filename: str):
        """Dataset'i JSON dosyasÄ±na kaydet"""
        output_path = PROJECT_ROOT / f"UniqeAi/ai_model/data/{filename}"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Dataset kaydedildi: {output_path}")
        print(f"ğŸ“ Dosya boyutu: {output_path.stat().st_size / 1024 / 1024:.2f} MB")