# ğŸ”¥ Llama-3.1-8B Fine-tuning Rehberi

Bu klasÃ¶rde bulunan scriptler ile Llama-3.1-8B-Instruct modelini TÃ¼rkÃ§e Ã§aÄŸrÄ± merkezi senaryolarÄ± iÃ§in fine-tune edebilirsiniz.

## ğŸ“ Dosya YapÄ±sÄ±

```
scripts/
â”œâ”€â”€ run_finetune.py          # Ana fine-tuning scripti (tam Ã¶zellikli)
â”œâ”€â”€ quick_finetune.py        # HÄ±zlÄ± baÅŸlangÄ±Ã§ scripti (basitleÅŸtirilmiÅŸ)
â”œâ”€â”€ data_structure.py        # Veri yapÄ±sÄ± oluÅŸturma (GÃ¼n 2)
â”œâ”€â”€ extended_data_generator.py # GeniÅŸletilmiÅŸ veri Ã¼retimi (GÃ¼n 2)  
â”œâ”€â”€ combine_datasets.py      # Veri setlerini birleÅŸtirme (GÃ¼n 2)
â”œâ”€â”€ turkish_preprocessing.py # TÃ¼rkÃ§e Ã¶n iÅŸleme (GÃ¼n 4)
â””â”€â”€ README_FINETUNE.md       # Bu dosya
```

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Sistem Gereksinimleri

**Minimum:**
- Python 3.8+
- 8GB RAM
- 10GB disk alanÄ±

**Ã–nerilen:**
- Python 3.10+
- NVIDIA GPU (8GB+ VRAM)
- 16GB RAM
- 50GB disk alanÄ±

### 2. Paket Kurulumu

```bash
# Ana dizinden Ã§alÄ±ÅŸtÄ±rÄ±n
pip install -r requirements.txt

# Opsiyonel: Flash Attention 2 (performans iÃ§in)
pip install flash-attn --no-build-isolation
```

### 3. Veri HazÄ±rlÄ±ÄŸÄ± (Zaten YapÄ±lmÄ±ÅŸ)

EÄŸer daha Ã¶nce yapÄ±lmamÄ±ÅŸsa:

```bash
cd ai_model/scripts
python data_structure.py
python extended_data_generator.py  
python combine_datasets.py
```

### 4. Fine-tuning BaÅŸlatma

**SeÃ§enek A: Quick Start (Yeni BaÅŸlayanlar Ä°Ã§in)**
```bash
cd ai_model/scripts
python quick_finetune.py
```

**SeÃ§enek B: Tam Kontrol**
```bash
cd ai_model/scripts
python run_finetune.py
```

## âš™ï¸ KonfigÃ¼rasyon SeÃ§enekleri

### GPU Bellek AyarlarÄ±

| GPU VRAM | Ã–nerilen Ayar | Batch Size | Quantization |
|----------|---------------|------------|--------------|
| 4-6 GB   | 4-bit + LoRA  | 1          | Zorunlu      |
| 8-12 GB  | 4-bit + LoRA  | 1-2        | Ã–nerilen     |
| 16+ GB   | 8-bit + LoRA  | 2-4        | Opsiyonel    |

### LoRA Parametreleri

```python
# Hafif fine-tuning (hÄ±zlÄ±, az deÄŸiÅŸiklik)
lora_config = LoraConfig(r=8, lora_alpha=16)

# Orta fine-tuning (varsayÄ±lan)
lora_config = LoraConfig(r=16, lora_alpha=32)

# AÄŸÄ±r fine-tuning (yavaÅŸ, Ã§ok deÄŸiÅŸiklik)
lora_config = LoraConfig(r=32, lora_alpha=64)
```

### EÄŸitim Parametreleri

```python
# HÄ±zlÄ± test (1 epoch)
num_train_epochs=1, learning_rate=2e-4

# Standart (3 epoch) - Ã–nerilen
num_train_epochs=3, learning_rate=1e-4

# KapsamlÄ± (5 epoch)
num_train_epochs=5, learning_rate=5e-5
```

## ğŸ“Š Veri Seti Bilgileri

### Mevcut Veri Seti
- **Dosya:** `../data/complete_training_dataset.json`
- **Boyut:** 47 veri noktasÄ±
- **Format:** Instruction-Input-Output
- **Dil:** TÃ¼rkÃ§e
- **Domain:** Ã‡aÄŸrÄ± merkezi + E-ticaret

### Veri Kategorileri
- ğŸ¢ **Telekom (34.0%):** 16 veri noktasÄ±
- ğŸ›’ **E-ticaret (66.0%):** 31 veri noktasÄ±
  - KullanÄ±cÄ± yÃ¶netimi
  - ÃœrÃ¼n yÃ¶netimi  
  - SipariÅŸ yÃ¶netimi
  - Analitik/Raporlama
  - Stok yÃ¶netimi
  - Promosyon yÃ¶netimi
  - MÃ¼ÅŸteri hizmetleri

## ğŸ”§ Sorun Giderme

### YaygÄ±n Hatalar

**1. CUDA Out of Memory**
```
Ã‡Ã¶zÃ¼m: 
- Batch size'Ä± azaltÄ±n (per_device_train_batch_size=1)
- 4-bit quantization kullanÄ±n
- Gradient checkpointing aktif edin
```

**2. Import Errors**
```
Ã‡Ã¶zÃ¼m:
- pip install -r requirements.txt
- Python sÃ¼rÃ¼mÃ¼nÃ¼ kontrol edin (3.8+)
- Virtual environment kullanÄ±n
```

**3. Veri DosyasÄ± BulunamadÄ±**
```
Ã‡Ã¶zÃ¼m:
- data_structure.py Ã§alÄ±ÅŸtÄ±rÄ±n
- combine_datasets.py Ã§alÄ±ÅŸtÄ±rÄ±n  
- Dosya yolunu kontrol edin
```

**4. Flash Attention HatasÄ±**
```
Ã‡Ã¶zÃ¼m:
- flash-attn kaldÄ±rÄ±n: pip uninstall flash-attn
- Script'te attn_implementation="flash_attention_2" satÄ±rÄ±nÄ± kaldÄ±rÄ±n
```

### Log DosyalarÄ±

Fine-tuning sÄ±rasÄ±nda oluÅŸturulan loglar:

```
scripts/
â”œâ”€â”€ training_logs/
â”‚   â””â”€â”€ training_20240622_143022.log
â”œâ”€â”€ fine_tuned_model/
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ training_log.json
```

## ğŸ“ˆ Performans Ä°puÃ§larÄ±

### 1. GPU Optimizasyonu
```python
# Flash Attention 2 kullanÄ±n (varsa)
attn_implementation="flash_attention_2"

# Gradient checkpointing
gradient_checkpointing=True

# BF16 precision
bf16=True
```

### 2. Veri Optimizasyonu
```python
# Packing kapatÄ±n (kÃ¼Ã§Ã¼k veri seti iÃ§in)
packing=False

# Max sequence length ayarlayÄ±n
max_seq_length=1024  # Veriye gÃ¶re ayarlayÄ±n
```

### 3. Memory Management
```python
# Gradient accumulation kullanÄ±n
gradient_accumulation_steps=8

# Batch size kÃ¼Ã§Ã¼k tutun
per_device_train_batch_size=1
```

## ğŸ¯ Sonraki AdÄ±mlar

Fine-tuning tamamlandÄ±ktan sonra:

1. **Model Test Etme**
   ```bash
   python test_model.py
   ```

2. **Backend Entegrasyonu**
   - Model'i backend/app/ klasÃ¶rÃ¼ne kopyala
   - API endpoint'leri oluÅŸtur

3. **Frontend Entegrasyonu**
   - Streamlit arayÃ¼zÃ¼ gÃ¼ncelle
   - Chat interface implement et

4. **Performans DeÄŸerlendirme**
   - BLEU score hesapla
   - Manuel deÄŸerlendirme yap
   - A/B test dÃ¼zenle

## ğŸ”— Ä°lgili Dosyalar

- `../data/README.md` - Veri seti detaylarÄ±
- `../../backend/README.md` - Backend entegrasyon
- `../../docs/CALISTIRMA_VE_TEST_REHBERI.md` - Genel kullanÄ±m rehberi

## ğŸ“ Destek

SorularÄ±nÄ±z iÃ§in:
- GitHub Issues
- Proje dokÃ¼mantasyonu
- Team Slack kanalÄ± 