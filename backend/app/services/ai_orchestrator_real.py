import logging
import asyncio
import json
import re
import torch
from typing import List, Dict, Any, Optional
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
from dataclasses import dataclass
from datetime import datetime
import uuid
import os
from dotenv import load_dotenv

# T√ºrk√ße NLP i√ßin
try:
    from zemberek import TurkishMorphology
    ZEMBEREK_AVAILABLE = True
except ImportError:
    ZEMBEREK_AVAILABLE = False
    print("Zemberek kurulu deƒüil. T√ºrk√ße NLP √∂zellikleri devre dƒ±≈üƒ±.")

# LangChain entegrasyonu
try:
    from langchain.llms import HuggingFacePipeline
    from langchain.prompts import PromptTemplate
    from langchain.chains import LLMChain
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("LangChain kurulu deƒüil. Geli≈ümi≈ü AI √∂zellikleri devre dƒ±≈üƒ±.")

logger = logging.getLogger(__name__)

@dataclass
class KonusmaMesaji:
    role: str  # "user" veya "assistant"
    content: str
    timestamp: datetime

@dataclass
class AracCagrisi:
    arac_adi: str
    parametreler: Dict[str, Any]
    durum: str = "bekliyor"
    sonuc: Optional[Dict[str, Any]] = None
    hata_mesaji: Optional[str] = None

class YapayZekaOrkestratori:
    def __init__(self):
        # AI model ve tokenizer
        self.model = None
        self.tokenizer = None
        self.morphology = None
        self.langchain_chain = None
        self._model_loaded = False
        
        # Model adƒ± - GGUF Telekom AI modeli
        self.model_name = "Choyrens/ChoyrensAI-Telekom-Agent-v4-gguf"
        
        # Yeni model yolu
        self.local_model_path = r"C:\Users\erkan\Desktop\ChoyrensAi-models\choyrens_model_v4_gguf"
        
        # T√ºrk√ße NLP i√ßin Zemberek
        try:
            from zemberek import TurkishMorphology
            self.morphology = TurkishMorphology.create_with_defaults()
            logger.info("Zemberek T√ºrk√ße NLP ba≈üarƒ±yla y√ºklendi")
        except ImportError:
            logger.warning("Zemberek bulunamadƒ±, basit T√ºrk√ße i≈üleme kullanƒ±lacak")
            self.morphology = None
        
        # Model y√ºkleme
        self._load_model()
    
    def _load_model(self):
        """GGUF Telekom AI modelini y√ºkle"""
        try:
            logger.info(f"AI modeli y√ºkleniyor: {self.model_name}")
            
            # GGUF model i√ßin llama-cpp-python kullan
            try:
                from llama_cpp import Llama
                import torch
                
                logger.info("GGUF Telekom AI modeli llama-cpp-python ile y√ºkleniyor...")
                
                # Yeni model yolu ile y√ºkle
                model_path = self.local_model_path
                
                logger.info(f"Model dosyasƒ±: {model_path}")
                
                # GGUF model y√ºkleme - llama-cpp-python ile
                self.model = Llama(
                    model_path=model_path,
                    n_ctx=2048,  # Context length
                    n_threads=4,  # Thread sayƒ±sƒ±
                    n_batch=1,  # Batch size
                    verbose=False  # Verbose kapalƒ±
                )
                
                # Tokenizer i√ßin basit bir wrapper
                class SimpleTokenizer:
                    def __init__(self):
                        self.pad_token = "<pad>"
                        self.eos_token = "</s>"
                        self.bos_token = "<s>"
                    
                    def encode(self, text, **kwargs):
                        # Basit tokenization
                        return text.split()
                    
                    def decode(self, tokens, **kwargs):
                        # Basit detokenization
                        return " ".join(tokens)
                
                self.tokenizer = SimpleTokenizer()
                
                # LangChain kurulumu
                if LANGCHAIN_AVAILABLE:
                    self._setup_langchain()
                
                self._model_loaded = True
                logger.info("‚úÖ GGUF Telekom AI modeli ba≈üarƒ±yla y√ºklendi!")
                
            except ImportError:
                logger.warning("llama-cpp-python bulunamadƒ±, basit AI kullanƒ±lacak")
                self._model_loaded = False
                
        except Exception as e:
            logger.error(f"‚ùå Model y√ºkleme hatasƒ±: {e}")
            self._model_loaded = False
            logger.info("‚ö†Ô∏è AI doƒüal yanƒ±t verecek - model y√ºkleme ba≈üarƒ±sƒ±z")
    
    def _setup_langchain(self):
        """LangChain pipeline kurulumu"""
        try:
            from transformers import pipeline
            
            # HuggingFace pipeline olu≈ütur
            pipe = pipeline(
                "text-generation",
                model=self.model,
                tokenizer=self.tokenizer,
                max_new_tokens=128,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1
            )
            
            # LangChain LLM wrapper
            llm = HuggingFacePipeline(pipeline=pipe)
            
            # Prompt template
            template = """Sen bir Telekom AI asistanƒ±sƒ±n. Kullanƒ±cƒ±nƒ±n sorununu anla ve uygun aracƒ± se√ß.

Mevcut ara√ßlar:
- get_past_bills: Ge√ßmi≈ü faturalar
- get_current_bill: Mevcut fatura
- get_available_packages: Kullanƒ±labilir paketler
- get_remaining_quotas: Kalan kotas
- check_network_status: Aƒü durumu
- test_internet_speed: ƒ∞nternet hƒ±zƒ± testi

Kullanƒ±cƒ±: {user_input}
Yanƒ±t:"""
            
            prompt = PromptTemplate(
                input_variables=["user_input"],
                template=template
            )
            
            self.langchain_chain = LLMChain(llm=llm, prompt=prompt)
            logger.info("LangChain pipeline ba≈üarƒ±yla kuruldu")
            
        except Exception as e:
            logger.error(f"LangChain kurulum hatasƒ±: {e}")
    
    def _turkish_preprocessing(self, text: str) -> str:
        """T√ºrk√ße metin √∂n i≈üleme"""
        if not ZEMBEREK_AVAILABLE or not self.morphology:
            return text.lower()
        
        try:
            # Zemberek ile lemmatization
            analysis = self.morphology.analyze(text)
            lemmas = []
            for result in analysis:
                if result.analysis:
                    lemmas.append(result.analysis[0].dictionary_item.lemma)
            
            return " ".join(lemmas).lower() if lemmas else text.lower()
        except Exception as e:
            logger.warning(f"T√ºrk√ße √∂n i≈üleme hatasƒ±: {e}")
            return text.lower()
    
    def _create_system_prompt(self, mevcut_araclar: Dict[str, Any]) -> str:
        """Geli≈ümi≈ü sistem promptu olu≈ütur"""
        
        return f"""Sen bir Telekom AI asistanƒ±sƒ±n. Kullanƒ±cƒ±nƒ±n sorununu anla ve uygun aracƒ± se√ß.

Mevcut ara√ßlar:
- get_past_bills: Ge√ßmi≈ü faturalar (ge√ßmi≈ü faturalarƒ±m, √∂nceki faturalar)
- get_current_bill: Mevcut fatura (≈üu anki fatura, g√ºncel fatura)
- get_available_packages: Kullanƒ±labilir paketler (paketler, tarifeler)
- get_remaining_quotas: Kalan kotas (kota, kullanƒ±m)
- check_network_status: Aƒü durumu (aƒü, baƒülantƒ±)
- test_internet_speed: ƒ∞nternet hƒ±zƒ± testi (hƒ±z testi, speed test)

Kurallar:
- Sadece tek bir ara√ß se√ß
- Liste yapma, a√ßƒ±klama yapma
- Sadece ara√ß adƒ±nƒ± yaz

√ñrnekler:
- "ge√ßmi≈ü faturalarƒ±m" ‚Üí get_past_bills
- "aƒü durumu" ‚Üí check_network_status
- "paketler" ‚Üí get_available_packages

Kullanƒ±cƒ± sorusu: """
    
    async def _generate_response(self, dialogue: List[Dict[str, str]]) -> str:
        """Geli≈ümi≈ü AI yanƒ±t √ºretimi"""
        try:
            # Son kullanƒ±cƒ± mesajƒ±nƒ± al
            user_message = ""
            for msg in reversed(dialogue):
                if msg["role"] == "user":
                    user_message = msg["content"]
                    break
            
            logger.info(f"AI modeli yanƒ±t √ºretiyor: {user_message}")
            
            # AI d√º≈ü√ºnce s√ºreci ba≈ülƒ±yor
            logger.info("ü§î AI D√ú≈û√úNCE S√úRECƒ∞ BA≈ûLIYOR...")
            logger.info(f"üìù Gelen mesaj: '{user_message}'")
            
            # T√ºrk√ße √∂n i≈üleme
            processed_message = self._turkish_preprocessing(user_message)
            logger.info(f"üîß ƒ∞≈ülenmi≈ü mesaj: '{processed_message}'")
            
            # AI analiz s√ºreci
            logger.info("üîç AI MESAJ ANALƒ∞Zƒ∞:")
            if "konya" in processed_message.lower():
                logger.info("   üìç Konum tespit edildi: Konya")
            if "telefon" in processed_message.lower() or "√ßekmiyor" in processed_message.lower():
                logger.info("   üì± Telefon/aƒü sorunu tespit edildi")
            if "fatura" in processed_message.lower() or "√∂deme" in processed_message.lower():
                logger.info("   üí∞ Fatura/√∂deme konusu tespit edildi")
            if "paket" in processed_message.lower():
                logger.info("   üì¶ Paket konusu tespit edildi")
            if "kota" in processed_message.lower():
                logger.info("   üìä Kota konusu tespit edildi")
            
            # GGUF modeli kullan (eƒüer y√ºkl√ºyse)
            if self._model_loaded and self.model:
                try:
                    logger.info("GGUF modeli yanƒ±t √ºretiyor...")
                    
                    # GGUF modeli ile yanƒ±t √ºret
                    response = self.model(
                        f"""Sen bir Telekom m√º≈üteri hizmetleri asistanƒ±sƒ±n. Kullanƒ±cƒ±nƒ±n mesajƒ±nƒ± analiz et ve d√º≈ü√ºnce s√ºrecini g√∂ster.

D√ú≈û√úNCE S√úRECƒ∞:
1. Kullanƒ±cƒ±nƒ±n konumunu ve durumunu analiz et
2. Hangi Telekom hizmeti ile ilgili olduƒüunu belirle
3. Uygun aracƒ± se√ß ve nedenini a√ßƒ±kla
4. Doƒüal bir yanƒ±t ver

√ñrnek d√º≈ü√ºnce s√ºreci:
- "konya yolundayƒ±m telefonum √ßekmiyor" 
  ‚Üí Kullanƒ±cƒ± Konya'da, telefon √ßekmiyor
  ‚Üí Aƒü durumu sorunu var
  ‚Üí check_network_status aracƒ±nƒ± kullanmalƒ±yƒ±m
  ‚Üí "Konya'da telefon √ßekme sorunu ya≈üƒ±yorsunuz. Aƒü durumunu kontrol ediyorum. [check_network_status]"

Telekom ara√ßlarƒ±:
- get_past_bills: Ge√ßmi≈ü faturalar, √∂nceki faturalar, fatura ge√ßmi≈üi
- get_current_bill: Mevcut fatura, ≈üu anki fatura, g√ºncel fatura
- get_available_packages: Kullanƒ±labilir paketler, tarifeler, paket se√ßenekleri
- get_remaining_quotas: Kalan kota, kullanƒ±m durumu, data kullanƒ±mƒ±
- check_network_status: Aƒü durumu, baƒülantƒ± durumu, sinyal
- test_internet_speed: ƒ∞nternet hƒ±zƒ± testi, speed test

Kullanƒ±cƒ±: {processed_message}
Asistan:""",
                        max_tokens=100,
                        temperature=0.3,
                        stop=["Kullanƒ±cƒ±:", "\n\n"]
                    )
                    
                    ai_response = response['choices'][0]['text'].strip()
                    logger.info(f"ü§ñ GGUF YANITI: '{ai_response}'")
                    
                    # AI d√º≈ü√ºnce s√ºreci analizi
                    logger.info("üß† AI D√ú≈û√úNCE ANALƒ∞Zƒ∞:")
                    if "check_network_status" in ai_response.lower():
                        logger.info("   ‚úÖ Aƒü durumu aracƒ± se√ßildi")
                    if "get_past_bills" in ai_response.lower():
                        logger.info("   ‚úÖ Ge√ßmi≈ü faturalar aracƒ± se√ßildi")
                    if "get_available_packages" in ai_response.lower():
                        logger.info("   ‚úÖ Kullanƒ±labilir paketler aracƒ± se√ßildi")
                    if "get_remaining_quotas" in ai_response.lower():
                        logger.info("   ‚úÖ Kalan kotalar aracƒ± se√ßildi")
                    
                    logger.info("üéØ AI D√ú≈û√úNCE S√úRECƒ∞ TAMAMLANDI")
                    return ai_response
                    
                except Exception as e:
                    logger.warning(f"GGUF modeli hatasƒ±, doƒüal yanƒ±t veriyor: {e}")
            
            # LangChain kullan (eƒüer mevcutsa ve model y√ºkl√ºyse)
            if LANGCHAIN_AVAILABLE and self.langchain_chain and self._model_loaded:
                try:
                    import asyncio
                    # Timeout ile invoke kullan
                    loop = asyncio.get_event_loop()
                    response = await asyncio.wait_for(
                        loop.run_in_executor(None, self.langchain_chain.invoke, {"user_input": processed_message}),
                        timeout=30.0  # 30 saniye timeout (artƒ±rƒ±ldƒ±)
                    )
                    logger.info(f"LangChain yanƒ±tƒ±: {response}")
                    return str(response).strip()
                except asyncio.TimeoutError:
                    logger.warning("LangChain timeout, AI doƒüal yanƒ±t veriyor")
                except Exception as e:
                    logger.warning(f"LangChain hatasƒ±, AI doƒüal yanƒ±t veriyor: {e}")
            
            # AI'nin kendi karar vermesi - geli≈ümi≈ü keyword detection
            logger.info("AI kendi kararƒ±nƒ± veriyor...")
            
            # AI sadece LangChain ile karar verir, keyword detection yok
            # Eƒüer LangChain timeout olursa, AI doƒüal yanƒ±t verir
            return "Anlƒ±yorum. Size en uygun hizmeti bulmak i√ßin d√º≈ü√ºn√ºyorum. Hangi konuda yardƒ±m istiyorsunuz?"
            
        except Exception as e:
            logger.error(f"AI yanƒ±t √ºretme hatasƒ±: {e}")
            return "AI ≈üu anda d√º≈ü√ºn√ºyor, l√ºtfen tekrar deneyin."
    
    async def _parse_tool_calls(self, text: str, session_token: str = None) -> List[AracCagrisi]:
        """AI yanƒ±tƒ±ndan ara√ß √ßaƒürƒ±larƒ±nƒ± parse et"""
        arac_cagrilari = []
        
        try:
            # AI yanƒ±tƒ±nƒ± temizle
            cleaned_text = text.strip().lower()
            logger.info(f"Parse edilecek metin: {cleaned_text}")
            
            # AI sadece LangChain yanƒ±tƒ±nƒ± parse eder
            # Keyword detection yok - AI kendi kararƒ±nƒ± verir
            
            # Eƒüer AI ara√ß adƒ± d√∂nd√ºrd√ºyse, onu kullan
            # Format: "A√ßƒ±klama. [get_past_bills]" veya sadece "get_past_bills"
            if "get_past_bills" in cleaned_text:
                arac_adi = "get_past_bills"
                parametreler = {"session_token": session_token} if session_token else {}
                arac_cagrilari.append(AracCagrisi(arac_adi, parametreler))
                logger.info(f"AI ara√ß se√ßti: {arac_adi}")
                
            elif "get_current_bill" in cleaned_text:
                arac_adi = "get_current_bill"
                parametreler = {"session_token": session_token} if session_token else {}
                arac_cagrilari.append(AracCagrisi(arac_adi, parametreler))
                logger.info(f"AI ara√ß se√ßti: {arac_adi}")
                
            elif "get_available_packages" in cleaned_text:
                arac_adi = "get_available_packages"
                parametreler = {}
                arac_cagrilari.append(AracCagrisi(arac_adi, parametreler))
                logger.info(f"AI ara√ß se√ßti: {arac_adi}")
                
            elif "get_remaining_quotas" in cleaned_text:
                arac_adi = "get_remaining_quotas"
                parametreler = {"session_token": session_token} if session_token else {}
                arac_cagrilari.append(AracCagrisi(arac_adi, parametreler))
                logger.info(f"AI ara√ß se√ßti: {arac_adi}")
                
            elif "check_network_status" in cleaned_text:
                arac_adi = "check_network_status"
                parametreler = {"session_token": session_token} if session_token else {}
                arac_cagrilari.append(AracCagrisi(arac_adi, parametreler))
                logger.info(f"AI ara√ß se√ßti: {arac_adi}")
                
            elif "test_internet_speed" in cleaned_text:
                arac_adi = "test_internet_speed"
                parametreler = {}
                arac_cagrilari.append(AracCagrisi(arac_adi, parametreler))
                logger.info(f"AI ara√ß se√ßti: {arac_adi}")
            
            logger.info(f"AI toplam {len(arac_cagrilari)} ara√ß se√ßti")
            
        except Exception as e:
            logger.error(f"Ara√ß parse hatasƒ±: {e}")
        
        return arac_cagrilari
    
    async def kullanici_mesaj_isle(self, mesaj: str, kullanici_id: str, oturum_id: str, session_token: str = None) -> Dict[str, Any]:
        """Ana mesaj i≈üleme fonksiyonu"""
        logger.info(f"AI Orchestrator'a iletilen session_token: {session_token}")
        
        try:
            logger.info(f"Kullanƒ±cƒ± mesajƒ± i≈üleniyor: {kullanici_id} - {mesaj[:50]}...")
            
            # Mesajƒ± √∂n i≈üle
            islenmis_mesaj = self._turkish_preprocessing(mesaj)
            logger.info(f"ƒ∞≈ülenmi≈ü mesaj: {islenmis_mesaj}")
            
            # Konu≈üma baƒülamƒ±nƒ± hazƒ±rla
            dialogue = [{"role": "user", "content": islenmis_mesaj}]
            logger.info(f"Baƒülam mesaj sayƒ±sƒ±: {len(dialogue)}")
            
            # Mevcut ara√ßlarƒ± hazƒ±rla
            mevcut_araclar = {
                "get_past_bills": "Ge√ßmi≈ü faturalar",
                "get_current_bill": "Mevcut fatura",
                "get_available_packages": "Kullanƒ±labilir paketler",
                "get_remaining_quotas": "Kalan kotas",
                "check_network_status": "Aƒü durumu",
                "test_internet_speed": "ƒ∞nternet hƒ±zƒ± testi"
            }
            logger.info(f"Mevcut ara√ß sayƒ±sƒ±: {len(mevcut_araclar)}")
            
            # AI yanƒ±tƒ± √ºret (model y√ºklenmese bile)
            logger.info("AI yanƒ±tƒ± √ºretiliyor...")
            ai_response = await self._generate_response(dialogue)
            logger.info(f"AI yanƒ±tƒ± √ºretildi: {ai_response[:100]}...")
            
            # Ara√ß √ßaƒürƒ±larƒ±nƒ± parse et
            logger.info("üîß ARA√á PARSE S√úRECƒ∞:")
            arac_cagrilari = await self._parse_tool_calls(ai_response, session_token)
            logger.info(f"üìä Ara√ß √ßaƒürƒ±sƒ± sayƒ±sƒ±: {len(arac_cagrilari)}")
            
            for i, arac in enumerate(arac_cagrilari):
                logger.info(f"   üõ†Ô∏è Ara√ß {i+1}: {arac.arac_adi}")
                logger.info(f"   üìã Parametreler: {arac.parametreler}")
            
            # Ara√ß √ßaƒürƒ±larƒ±nƒ± y√ºr√ºt
            if arac_cagrilari:
                logger.info(f"üöÄ {len(arac_cagrilari)} ARA√á Y√úR√úTME S√úRECƒ∞:")
                for i, arac in enumerate(arac_cagrilari):
                    logger.info(f"   üîÑ Ara√ß {i+1} y√ºr√ºt√ºl√ºyor: {arac.arac_adi}")
                    try:
                        # Telekom API √ßaƒürƒ±sƒ±
                        logger.info(f"   üìû Telekom API'ye √ßaƒürƒ± yapƒ±lƒ±yor...")
                        sonuc = await self._telekom_arac_cagir(arac.arac_adi, arac.parametreler)
                        arac.sonuc = sonuc
                        arac.durum = "tamamlandi"
                        logger.info(f"   ‚úÖ Ara√ß {i+1} ba≈üarƒ±lƒ±: {arac.arac_adi}")
                        logger.info(f"   üìä Sonu√ß: {str(sonuc)[:100]}...")
                    except Exception as e:
                        logger.error(f"   ‚ùå Ara√ß {i+1} hatasƒ±: {arac.arac_adi} - {e}")
                        arac.durum = "hata"
                        arac.hata_mesaji = str(e)
            
            # Final yanƒ±t √ºret
            logger.info("Final yanƒ±t √ºretiliyor...")
            final_yanit = self._arac_sonuclarini_entegre_et(ai_response, arac_cagrilari)
            logger.info(f"Final yanƒ±t: {final_yanit[:100]}...")
            
            # Sonucu hazƒ±rla
            sonuc = {
                "yanit_id": f"YANIT_{uuid.uuid4().hex[:8]}",
                "yanit": final_yanit,
                "guven_puani": 0.9 if self._model_loaded else 0.7,
                "arac_cagrilari": [
                    {
                        "arac_adi": arac.arac_adi,
                        "parametreler": arac.parametreler,
                        "durum": arac.durum,
                        "sonuc": arac.sonuc,
                        "hata_mesaji": arac.hata_mesaji
                    }
                    for arac in arac_cagrilari
                ],
                "metadata": {
                    "oturum_id": oturum_id,
                    "kullanici_id": kullanici_id,
                    "islenme_zamani": datetime.now().isoformat(),
                    "baglam_mesaj_sayisi": len(dialogue),
                    "model_loaded": self._model_loaded
                }
            }
            
            logger.info(f"Mesaj i≈üleme tamamlandƒ±: {sonuc['yanit_id']}")
            return sonuc
            
        except Exception as e:
            logger.error(f"Mesaj i≈üleme hatasƒ±: {e}")
            # Hata durumunda bile AI yanƒ±tƒ± √ºret
            return {
                "yanit_id": f"ERROR_{uuid.uuid4().hex[:8]}",
                "yanit": "AI ≈üu anda d√º≈ü√ºn√ºyor, l√ºtfen tekrar deneyin.",
                "guven_puani": 0.5,
                "arac_cagrilari": [],
                "metadata": {
                    "oturum_id": oturum_id,
                    "kullanici_id": kullanici_id,
                    "islenme_zamani": datetime.now().isoformat(),
                    "error": str(e)
                }
            }
    
    async def _fallback_response(self, mesaj: str, session_token: str = None) -> Dict[str, Any]:
        """Model y√ºklenmediƒüinde fallback yanƒ±t"""
        # Basit keyword detection
        mesaj_lower = mesaj.lower()
        
        if any(word in mesaj_lower for word in ["ge√ßmi≈ü", "fatura", "√∂deme"]):
            arac_adi = "get_past_bills"
            parametreler = {"session_token": session_token, "limit": 12} if session_token else {"limit": 12}
        elif any(word in mesaj_lower for word in ["paket", "tarife"]):
            arac_adi = "get_available_packages"
            parametreler = {}
        elif any(word in mesaj_lower for word in ["kota", "kullanƒ±m"]):
            arac_adi = "get_remaining_quotas"
            parametreler = {"session_token": session_token} if session_token else {}
        elif any(word in mesaj_lower for word in ["aƒü", "baƒülantƒ±"]):
            arac_adi = "check_network_status"
            parametreler = {"region": "Istanbul"}
        else:
            arac_adi = "get_past_bills"
            parametreler = {"session_token": session_token, "limit": 12} if session_token else {"limit": 12}
        
        # Ara√ß √ßaƒürƒ±sƒ± yap
        try:
            sonuc = await self._telekom_arac_cagir(arac_adi, parametreler)
            durum = "tamamlandi"
            hata_mesaji = None
        except Exception as e:
            sonuc = None
            durum = "hata"
            hata_mesaji = str(e)
        
        return {
            "yanit_id": f"FALLBACK_{uuid.uuid4().hex[:8]}",
            "yanit": f"Fallback yanƒ±t: {arac_adi} √ßaƒürƒ±ldƒ±",
            "guven_puani": 0.5,
            "arac_cagrilari": [
                {
                    "arac_adi": arac_adi,
                    "parametreler": parametreler,
                    "durum": durum,
                    "sonuc": sonuc,
                    "hata_mesaji": hata_mesaji
                }
            ],
            "metadata": {
                "oturum_id": "FALLBACK",
                "kullanici_id": "FALLBACK",
                "islenme_zamani": datetime.now().isoformat(),
                "baglam_mesaj_sayisi": 0
            }
        }
    
    async def _telekom_arac_cagir(self, arac_adi: str, parametreler: Dict[str, Any]) -> Any:
        """Telekom API ara√ß √ßaƒürƒ±sƒ±"""
        try:
            logger.info(f"AI Telekom ara√ß √ßaƒürƒ±sƒ±: {arac_adi} - {parametreler}")
            
            # AI endpoint fonksiyonlarƒ± mapping
            from .ai_endpoint_functions import ai_endpoint_functions
            
            function_mapping = {
                "get_current_bill": ai_endpoint_functions.telekom_get_current_bill,
                "get_past_bills": ai_endpoint_functions.telekom_get_bill_history,
                "get_available_packages": ai_endpoint_functions.telekom_get_available_packages,
                "get_remaining_quotas": ai_endpoint_functions.telekom_get_remaining_quotas,
                "check_network_status": ai_endpoint_functions.telekom_check_network_status,
                "test_internet_speed": ai_endpoint_functions.telekom_test_internet_speed,
            }
            
            if arac_adi not in function_mapping:
                logger.warning(f"Bilinmeyen ara√ß: {arac_adi}")
                return None
            
            # Fonksiyonu √ßaƒüƒ±r
            function = function_mapping[arac_adi]
            logger.info(f"Ara√ß √ßaƒürƒ±sƒ±: {arac_adi} -> {function.__name__}")
            result = await function(**parametreler)
            
            logger.info(f"AI Telekom API yanƒ±tƒ±: {result}")
            return result
            
        except Exception as e:
            logger.error(f"AI Telekom ara√ß √ßaƒürƒ±sƒ± hatasƒ±: {e}")
            raise
    
    def _arac_sonuclarini_entegre_et(self, temel_yanit: str, arac_sonuclari: List[AracCagrisi]) -> str:
        """Ara√ß sonu√ßlarƒ±nƒ± yanƒ±ta entegre et"""
        if not arac_sonuclari:
            return temel_yanit
        
        # Basit entegrasyon
        basarili_sonuclar = [arac for arac in arac_sonuclari if arac.durum == "tamamlandi"]
        
        if basarili_sonuclar:
            return f"ƒ∞≈üleminiz tamamlandƒ±. {len(basarili_sonuclar)} ara√ß ba≈üarƒ±yla √ßalƒ±≈ütƒ±rƒ±ldƒ±."
        else:
            return "√úzg√ºn√ºm, i≈üleminiz sƒ±rasƒ±nda bir hata olu≈ütu."
    
    async def sistem_durumu_getir(self) -> Dict[str, Any]:
        """Sistem durumu bilgilerini getir"""
        return {
            "status": "healthy",
            "model_loaded": self._model_loaded,
            "model_name": self.model_name,
            "turkish_nlp": ZEMBEREK_AVAILABLE,
            "langchain_available": LANGCHAIN_AVAILABLE,
            "timestamp": datetime.now().isoformat(),
            "version": "2.0.0"
        }

# Global orkestrat√∂r √∂rneƒüi
ai_orchestrator = YapayZekaOrkestratori() 