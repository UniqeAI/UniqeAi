import logging
import asyncio
import json
import re
import torch
from typing import List, Dict, Any, Optional
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
from dataclasses import dataclass
from datetime import datetime
import uuid
import os
from dotenv import load_dotenv

# TÃ¼rkÃ§e NLP iÃ§in
try:
    from zemberek import TurkishMorphology
    ZEMBEREK_AVAILABLE = True
except ImportError:
    ZEMBEREK_AVAILABLE = False
    print("Zemberek kurulu deÄŸil. TÃ¼rkÃ§e NLP Ã¶zellikleri devre dÄ±ÅŸÄ±.")

# LangChain entegrasyonu
try:
    from langchain_community.llms import HuggingFacePipeline
    from langchain.prompts import PromptTemplate
    from langchain.chains import LLMChain
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("LangChain kurulu deÄŸil. GeliÅŸmiÅŸ AI Ã¶zellikleri devre dÄ±ÅŸÄ±.")

logger = logging.getLogger(__name__)

@dataclass
class KonusmaMesaji:
    role: str  # "user" veya "assistant"
    content: str
    timestamp: datetime

@dataclass
class AracCagrisi:
    arac_adi: str
    parametreler: Dict[str, Any]
    durum: str = "bekliyor"
    sonuc: Optional[Dict[str, Any]] = None
    hata_mesaji: Optional[str] = None

class YapayZekaOrkestratori:
    def __init__(self):
        # AI model ve tokenizer
        self.model = None
        self.tokenizer = None
        self.morphology = None
        self.langchain_chain = None
        self._model_loaded = False
        
        # Model adÄ± - GGUF Telekom AI modeli (v5 eklendi)
        self.model_name = "Choyrens/ChoyrensAI-Telekom-Agent-v5-gguf"
        
        # TÃ¼rkÃ§e NLP iÃ§in Zemberek
        try:
            from zemberek import TurkishMorphology
            self.morphology = TurkishMorphology.create_with_defaults()
            logger.info("Zemberek TÃ¼rkÃ§e NLP baÅŸarÄ±yla yÃ¼klendi")
        except ImportError:
            logger.warning("Zemberek bulunamadÄ±, basit TÃ¼rkÃ§e iÅŸleme kullanÄ±lacak")
            self.morphology = None
        
        # Model yÃ¼kleme
        self._load_model()
    
    def _load_model(self):
        """GGUF Telekom AI modelini yÃ¼kle"""
        try:
            logger.info(f"AI modeli yÃ¼kleniyor: {self.model_name}")
            
            # GGUF model iÃ§in llama-cpp-python kullan
            try:
                from llama_cpp import Llama
                import torch
                
                logger.info("GGUF Telekom AI modeli llama-cpp-python ile yÃ¼kleniyor...")
                
                # Model yolu - v5 iÃ§in dinamik yÃ¼kleme
                import os
                from huggingface_hub import snapshot_download
                
                # Model'i Hugging Face'den indir
                model_path = snapshot_download(
                    repo_id=self.model_name,
                    local_dir="./models"
                )
                
                # GGUF dosyasÄ±nÄ± bul
                gguf_files = [f for f in os.listdir(model_path) if f.endswith('.gguf')]
                if gguf_files:
                    model_file = os.path.join(model_path, gguf_files[0])
                else:
                    raise FileNotFoundError(f"GGUF dosyasÄ± bulunamadÄ±: {model_path}")
                
                logger.info(f"Model dosyasÄ±: {model_path}")
                
                # GGUF model yÃ¼kleme - llama-cpp-python ile (v5 iÃ§in optimize edildi)
                self.model = Llama(
                    model_path=model_file,
                    n_ctx=8192,  # Context length artÄ±rÄ±ldÄ± (v5 iÃ§in maksimum)
                    n_threads=16,  # Thread sayÄ±sÄ±nÄ± artÄ±r
                    n_batch=32,  # Batch size artÄ±r
                    n_gpu_layers=0,  # CPU kullan
                    verbose=False,  # Verbose kapalÄ±
                    use_mlock=True,  # Memory locking
                    use_mmap=True,  # Memory mapping
                    seed=42  # Deterministic results
                )
                
                # Tokenizer iÃ§in basit bir wrapper
                class SimpleTokenizer:
                    def __init__(self):
                        self.pad_token = "<pad>"
                        self.eos_token = "</s>"
                        self.bos_token = "<s>"
                    
                    def encode(self, text, **kwargs):
                        # Basit tokenization
                        return text.split()
                    
                    def decode(self, tokens, **kwargs):
                        # Basit detokenization
                        return " ".join(tokens)
                
                self.tokenizer = SimpleTokenizer()
                
                # LangChain kurulumu
                if LANGCHAIN_AVAILABLE:
                    self._setup_langchain()
                
                self._model_loaded = True
                logger.info("âœ… GGUF Telekom AI modeli baÅŸarÄ±yla yÃ¼klendi!")
                
            except ImportError:
                logger.warning("llama-cpp-python bulunamadÄ±, basit AI kullanÄ±lacak")
                self._model_loaded = False
                
        except Exception as e:
            logger.error(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
            self._model_loaded = False
            logger.info("âš ï¸ AI doÄŸal yanÄ±t verecek - model yÃ¼kleme baÅŸarÄ±sÄ±z")
    
    def _setup_langchain(self):
        """LangChain pipeline kurulumu"""
        try:
            from transformers import pipeline
            
            # HuggingFace pipeline oluÅŸtur
            pipe = pipeline(
                "text-generation",
                model=self.model,
                tokenizer=self.tokenizer,
                max_new_tokens=128,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1
            )
            
            # LangChain LLM wrapper
            llm = HuggingFacePipeline(pipeline=pipe)
            
            # Prompt template - AI'ya mantÄ±klÄ± yÃ¶nlendirme
            template = """Sen bir Telekom AI asistanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorununu mantÄ±klÄ± bir ÅŸekilde anla ve uygun Ã§Ã¶zÃ¼m Ã¶ner.

KullanÄ±cÄ±: {user_input}
YanÄ±t:"""
            
            prompt = PromptTemplate(
                input_variables=["user_input"],
                template=template
            )
            
            self.langchain_chain = LLMChain(llm=llm, prompt=prompt)
            logger.info("LangChain pipeline baÅŸarÄ±yla kuruldu")
            
        except Exception as e:
            logger.error(f"LangChain kurulum hatasÄ±: {e}")
    
    def _turkish_preprocessing(self, text: str) -> str:
        """TÃ¼rkÃ§e metin Ã¶n iÅŸleme"""
        if not ZEMBEREK_AVAILABLE or not self.morphology:
            return text.lower()
        
        try:
            # Zemberek ile lemmatization - gÃ¼ncellenmiÅŸ API kullanÄ±mÄ±
            analysis = self.morphology.analyze(text)
            lemmas = []
            for result in analysis:
                # Zemberek API'sinin farklÄ± versiyonlarÄ± iÃ§in uyumluluk
                if hasattr(result, 'analysis') and result.analysis:
                    lemmas.append(result.analysis[0].dictionary_item.lemma)
                elif hasattr(result, 'dictionary_item') and result.dictionary_item:
                    lemmas.append(result.dictionary_item.lemma)
                elif hasattr(result, 'lemma'):
                    lemmas.append(result.lemma)
                else:
                    # EÄŸer hiÃ§biri Ã§alÄ±ÅŸmazsa, orijinal kelimeyi kullan
                    continue
            
            return " ".join(lemmas).lower() if lemmas else text.lower()
        except Exception as e:
            logger.warning(f"TÃ¼rkÃ§e Ã¶n iÅŸleme hatasÄ±: {e}")
            return text.lower()
    
    async def _generate_response(self, dialogue: List[Dict[str, str]]) -> str:
        """AI yanÄ±t Ã¼retimi - AI'ya mantÄ±klÄ± yÃ¶nlendirme"""
        try:
            # Son kullanÄ±cÄ± mesajÄ±nÄ± al
            user_message = ""
            for msg in reversed(dialogue):
                if msg["role"] == "user":
                    user_message = msg["content"]
                    break
            
            logger.info(f"AI modeli yanÄ±t Ã¼retiyor: {user_message}")
            
            # GGUF modeli kullan (eÄŸer yÃ¼klÃ¼yse)
            if self._model_loaded and self.model:
                try:
                    logger.info("GGUF modeli yanÄ±t Ã¼retiyor...")
                    
                    # AI'ya mantÄ±klÄ± yÃ¶nlendirme veren prompt
                    prompt = f"""<|im_start|>system
Sen Choyrens AI, Telekom mÃ¼ÅŸteri hizmetleri asistanÄ±sÄ±n. KullanÄ±cÄ±yla mantÄ±klÄ± ve tutarlÄ± bir konuÅŸma yap.

KÄ°ÅÄ°LÄ°ÄÄ°N:
- Samimi ve yardÄ±msever ol
- Telekom hizmetleri konusunda uzman ol
- MantÄ±klÄ± ve tutarlÄ± yanÄ±tlar ver
- KullanÄ±cÄ±nÄ±n sorununu anla ve Ã§Ã¶zÃ¼m Ã¶ner
- Gereksiz teknik terimler kullanma
- DoÄŸal TÃ¼rkÃ§e konuÅŸ

YANIT TARZIN:
- "Merhaba! Size nasÄ±l yardÄ±mcÄ± olabilirim?" gibi samimi
- "AnlÄ±yorum, bu durum gerÃ§ekten zor olabilir" gibi empatik
- "Hemen kontrol edeyim" gibi yardÄ±msever
- "Size en uygun Ã§Ã¶zÃ¼mÃ¼ bulacaÄŸÄ±m" gibi gÃ¼ven verici

MANTIKLI YÃ–NLENDÄ°RME:
- KullanÄ±cÄ±nÄ±n sorununu anla
- Uygun Telekom hizmetini Ã¶ner
- GerektiÄŸinde araÃ§ Ã§aÄŸÄ±r
- TutarlÄ± ve anlaÅŸÄ±lÄ±r yanÄ±tlar ver
- Konu dÄ±ÅŸÄ±na Ã§Ä±kma

ARAÃ‡ Ã‡AÄRISI: GerektiÄŸinde araÃ§ Ã§aÄŸÄ±r. Format: [arac_adi]

Telekom araÃ§larÄ±:
- get_current_package: Mevcut paket bilgisi
- get_past_bills: GeÃ§miÅŸ faturalar
- get_current_bill: Mevcut fatura
- check_network_status: AÄŸ durumu
- test_internet_speed: Ä°nternet hÄ±zÄ± testi
- get_remaining_quotas: Kalan kotas
- get_available_packages: KullanÄ±labilir paketler
- get_customer_profile: MÃ¼ÅŸteri profili
- create_support_ticket: Destek talebi oluÅŸturma
- pay_bill: Fatura Ã¶deme
- setup_autopay: Otomatik Ã¶deme
- get_payment_history: Ã–deme geÃ§miÅŸi
- change_package: Paket deÄŸiÅŸtirme
- get_package_details: Paket detaylarÄ±
- update_customer_contact: Ä°letiÅŸim bilgisi gÃ¼ncelleme
- enable_roaming: YurtdÄ±ÅŸÄ± hizmetleri
- suspend_line: Hat askÄ±ya alma
- reactivate_line: Hat aktifleÅŸtirme
- close_support_ticket: Destek talebi kapatma
- get_support_ticket_status: Destek talebi durumu
- get_user_support_tickets: Destek talepleri listesi
- auth_register: KayÄ±t olma
- auth_login: GiriÅŸ yapma

Ã–NEMLÄ°: MantÄ±klÄ± ve tutarlÄ± yanÄ±tlar ver, Telekom odaklÄ± kal.
<|im_end|>
<|im_start|>user
{user_message}
<|im_end|>
<|im_start|>assistant
"""
                    
                    # Model Ã§aÄŸrÄ±sÄ± - mantÄ±klÄ± yÃ¶nlendirme iÃ§in optimize edildi
                    response = self.model(
                        prompt,
                        max_tokens=2048,
                        temperature=0.7,  # Daha tutarlÄ±
                        top_p=0.9,  # Daha odaklÄ±
                        repeat_penalty=1.1,  # TekrarÄ± azalt
                        stop=["<|im_end|>", "<|im_start|>"]
                    )
                    
                    # Response parsing
                    if hasattr(response, 'choices') and response.choices:
                        ai_response = response.choices[0].text.strip()
                    elif hasattr(response, 'text'):
                        ai_response = response.text.strip()
                    elif isinstance(response, dict) and 'choices' in response:
                        ai_response = response['choices'][0]['text'].strip()
                    else:
                        ai_response = str(response).strip()
                    
                    # Response temizleme
                    ai_response = ai_response.replace('<|im_start|>', '').replace('<|im_end|>', '').strip()
                    logger.info(f"ğŸ¤– GGUF YANITI: '{ai_response}'")
                    
                    return ai_response
                    
                except Exception as e:
                    logger.warning(f"GGUF modeli hatasÄ±, doÄŸal yanÄ±t veriyor: {e}")
            
            # LangChain kullan (eÄŸer mevcutsa ve model yÃ¼klÃ¼yse)
            if LANGCHAIN_AVAILABLE and self.langchain_chain and self._model_loaded:
                try:
                    import asyncio
                    # Timeout ile invoke kullan
                    loop = asyncio.get_event_loop()
                    response = await asyncio.wait_for(
                        loop.run_in_executor(None, self.langchain_chain.invoke, {"user_input": user_message}),
                        timeout=30.0
                    )
                    logger.info(f"LangChain yanÄ±tÄ±: {response}")
                    return str(response).strip()
                except asyncio.TimeoutError:
                    logger.warning("LangChain timeout, AI doÄŸal yanÄ±t veriyor")
                except Exception as e:
                    logger.warning(f"LangChain hatasÄ±, AI doÄŸal yanÄ±t veriyor: {e}")
            
            # AI'nin mantÄ±klÄ± yanÄ±tÄ±
            logger.info("AI mantÄ±klÄ± yanÄ±t veriyor...")
            return "Merhaba! Ben Choyrens AI, Telekom mÃ¼ÅŸteri hizmetleri asistanÄ±nÄ±zÄ±m. Size nasÄ±l yardÄ±mcÄ± olabilirim? Fatura, paket, teknik destek veya baÅŸka bir konuda sorularÄ±nÄ±zÄ± yanÄ±tlayabilirim. ğŸ˜Š"
            
        except Exception as e:
            logger.error(f"AI yanÄ±t Ã¼retme hatasÄ±: {e}")
            return "ÃœzgÃ¼nÃ¼m, ÅŸu anda bir sorun yaÅŸÄ±yorum. LÃ¼tfen bir dakika sonra tekrar deneyin! ğŸ˜…"
    
    async def _parse_tool_calls(self, text: str, session_token: str = None) -> List[AracCagrisi]:
        """AI yanÄ±tÄ±ndan araÃ§ Ã§aÄŸrÄ±larÄ±nÄ± parse et - minimum mÃ¼dahale"""
        arac_cagrilari = []
        
        try:
            # AI yanÄ±tÄ±nÄ± temizle
            cleaned_text = text.strip()
            logger.info(f"Parse edilecek metin: {cleaned_text}")
            
            # Sadece aÃ§Ä±k araÃ§ Ã§aÄŸrÄ±larÄ±nÄ± bul - AI'nin kendi kararÄ±nÄ± vermesine izin ver
            import re
            
            # Regex ile araÃ§ Ã§aÄŸrÄ±larÄ±nÄ± bul - sadece aÃ§Ä±k format
            tool_pattern = r'\[([a-zA-Z_]+)\]'
            tool_matches = re.findall(tool_pattern, text)
            
            for tool_name in tool_matches:
                # Basit araÃ§ mapping - AI'nin kendi kararÄ±nÄ± vermesine izin ver
                valid_tools = [
                    "get_current_package", "get_past_bills", "get_current_bill", 
                    "check_network_status", "test_internet_speed", "get_remaining_quotas",
                    "get_available_packages", "get_customer_profile", "create_support_ticket",
                    "pay_bill", "setup_autopay", "get_payment_history", "change_package",
                    "get_package_details", "update_customer_contact", "enable_roaming",
                    "suspend_line", "reactivate_line", "close_support_ticket",
                    "get_support_ticket_status", "get_user_support_tickets",
                    "auth_register", "auth_login"
                ]
                
                if tool_name in valid_tools:
                    parametreler = {"session_token": session_token} if session_token else {}
                    arac_cagrilari.append(AracCagrisi(tool_name, parametreler))
                    logger.info(f"AI araÃ§ seÃ§ti: {tool_name}")
            
            logger.info(f"AI toplam {len(arac_cagrilari)} araÃ§ seÃ§ti")
            
        except Exception as e:
            logger.error(f"AraÃ§ parse hatasÄ±: {e}")
        
        return arac_cagrilari
    
    async def kullanici_mesaj_isle(self, mesaj: str, kullanici_id: str, oturum_id: str, session_token: str = None) -> Dict[str, Any]:
        """Ana mesaj iÅŸleme fonksiyonu - AI'ya minimum mÃ¼dahale"""
        logger.info(f"AI Orchestrator'a iletilen session_token: {session_token}")
        
        try:
            logger.info(f"KullanÄ±cÄ± mesajÄ± iÅŸleniyor: {kullanici_id} - {mesaj[:50]}...")
            
            # KonuÅŸma baÄŸlamÄ±nÄ± hazÄ±rla - AI'nin doÄŸal akÄ±ÅŸÄ±nÄ± bozma
            dialogue = [{"role": "user", "content": mesaj}]
            logger.info(f"BaÄŸlam mesaj sayÄ±sÄ±: {len(dialogue)}")
            
            # AI yanÄ±tÄ± Ã¼ret - minimum mÃ¼dahale
            logger.info("AI yanÄ±tÄ± Ã¼retiliyor...")
            ai_response = await self._generate_response(dialogue)
            logger.info(f"AI yanÄ±tÄ± Ã¼retildi: {ai_response[:100]}...")
            
            # AraÃ§ Ã§aÄŸrÄ±larÄ±nÄ± parse et - sadece aÃ§Ä±k Ã§aÄŸrÄ±lar
            logger.info("ğŸ”§ ARAÃ‡ PARSE SÃœRECÄ°:")
            arac_cagrilari = await self._parse_tool_calls(ai_response, session_token)
            logger.info(f"ğŸ“Š AraÃ§ Ã§aÄŸrÄ±sÄ± sayÄ±sÄ±: {len(arac_cagrilari)}")
            
            for i, arac in enumerate(arac_cagrilari):
                logger.info(f"   ğŸ› ï¸ AraÃ§ {i+1}: {arac.arac_adi}")
                logger.info(f"   ğŸ“‹ Parametreler: {arac.parametreler}")
            
            # AraÃ§ Ã§aÄŸrÄ±larÄ±nÄ± yÃ¼rÃ¼t - AI'nin kararÄ±nÄ± destekle
            if arac_cagrilari:
                logger.info(f"ğŸš€ {len(arac_cagrilari)} ARAÃ‡ YÃœRÃœTME SÃœRECÄ°:")
                for i, arac in enumerate(arac_cagrilari):
                    logger.info(f"   ğŸ”„ AraÃ§ {i+1} yÃ¼rÃ¼tÃ¼lÃ¼yor: {arac.arac_adi}")
                    try:
                        # Telekom API Ã§aÄŸrÄ±sÄ±
                        logger.info(f"   ğŸ“ Telekom API'ye Ã§aÄŸrÄ± yapÄ±lÄ±yor...")
                        sonuc = await self._telekom_arac_cagir(arac.arac_adi, arac.parametreler)
                        arac.sonuc = sonuc
                        arac.durum = "tamamlandi"
                        logger.info(f"   âœ… AraÃ§ {i+1} baÅŸarÄ±lÄ±: {arac.arac_adi}")
                        logger.info(f"   ğŸ“Š SonuÃ§: {str(sonuc)[:100]}...")
                    except Exception as e:
                        logger.error(f"   âŒ AraÃ§ {i+1} hatasÄ±: {arac.arac_adi} - {e}")
                        arac.durum = "hata"
                        arac.hata_mesaji = str(e)
            
            # Final yanÄ±t - AI'nin yanÄ±tÄ±nÄ± koru
            logger.info("Final yanÄ±t hazÄ±rlanÄ±yor...")
            final_yanit = ai_response  # AI'nin yanÄ±tÄ±nÄ± olduÄŸu gibi kullan
            
            # Sonucu hazÄ±rla
            sonuc = {
                "yanit_id": f"YANIT_{uuid.uuid4().hex[:8]}",
                "yanit": final_yanit,
                "guven_puani": 0.9 if self._model_loaded else 0.7,
                "arac_cagrilari": [
                    {
                        "arac_adi": arac.arac_adi,
                        "parametreler": arac.parametreler,
                        "durum": arac.durum,
                        "sonuc": arac.sonuc,
                        "hata_mesaji": arac.hata_mesaji
                    }
                    for arac in arac_cagrilari
                ],
                "metadata": {
                    "oturum_id": oturum_id,
                    "kullanici_id": kullanici_id,
                    "islenme_zamani": datetime.now().isoformat(),
                    "baglam_mesaj_sayisi": len(dialogue),
                    "model_loaded": self._model_loaded
                }
            }
            
            logger.info(f"Mesaj iÅŸleme tamamlandÄ±: {sonuc['yanit_id']}")
            return sonuc
            
        except Exception as e:
            logger.error(f"Mesaj iÅŸleme hatasÄ±: {e}")
            # Hata durumunda bile AI yanÄ±tÄ± Ã¼ret
            return {
                "yanit_id": f"ERROR_{uuid.uuid4().hex[:8]}",
                "yanit": "AI ÅŸu anda dÃ¼ÅŸÃ¼nÃ¼yor, lÃ¼tfen tekrar deneyin.",
                "guven_puani": 0.5,
                "arac_cagrilari": [],
                "metadata": {
                    "oturum_id": oturum_id,
                    "kullanici_id": kullanici_id,
                    "islenme_zamani": datetime.now().isoformat(),
                    "error": str(e)
                }
            }
    
    async def _fallback_response(self, mesaj: str, session_token: str = None) -> Dict[str, Any]:
        """Model yÃ¼klenmediÄŸinde fallback yanÄ±t"""
        # Basit keyword detection
        mesaj_lower = mesaj.lower()
        
        if any(word in mesaj_lower for word in ["geÃ§miÅŸ", "fatura", "Ã¶deme"]):
            arac_adi = "get_past_bills"
            parametreler = {"session_token": session_token, "limit": 12} if session_token else {"limit": 12}
        elif any(word in mesaj_lower for word in ["paket", "tarife"]):
            arac_adi = "get_available_packages"
            parametreler = {}
        elif any(word in mesaj_lower for word in ["kota", "kullanÄ±m"]):
            arac_adi = "get_remaining_quotas"
            parametreler = {"session_token": session_token} if session_token else {}
        elif any(word in mesaj_lower for word in ["aÄŸ", "baÄŸlantÄ±"]):
            arac_adi = "check_network_status"
            parametreler = {"region": "Istanbul"}
        else:
            arac_adi = "get_past_bills"
            parametreler = {"session_token": session_token, "limit": 12} if session_token else {"limit": 12}
        
        # AraÃ§ Ã§aÄŸrÄ±sÄ± yap
        try:
            sonuc = await self._telekom_arac_cagir(arac_adi, parametreler)
            durum = "tamamlandi"
            hata_mesaji = None
        except Exception as e:
            sonuc = None
            durum = "hata"
            hata_mesaji = str(e)
        
        return {
            "yanit_id": f"FALLBACK_{uuid.uuid4().hex[:8]}",
            "yanit": f"Fallback yanÄ±t: {arac_adi} Ã§aÄŸrÄ±ldÄ±",
            "guven_puani": 0.5,
            "arac_cagrilari": [
                {
                    "arac_adi": arac_adi,
                    "parametreler": parametreler,
                    "durum": durum,
                    "sonuc": sonuc,
                    "hata_mesaji": hata_mesaji
                }
            ],
            "metadata": {
                "oturum_id": "FALLBACK",
                "kullanici_id": "FALLBACK",
                "islenme_zamani": datetime.now().isoformat(),
                "baglam_mesaj_sayisi": 0
            }
        }
    
    async def _telekom_arac_cagir(self, arac_adi: str, parametreler: Dict[str, Any]) -> Any:
        """Telekom API araÃ§ Ã§aÄŸrÄ±sÄ±"""
        try:
            logger.info(f"AI Telekom araÃ§ Ã§aÄŸrÄ±sÄ±: {arac_adi} - {parametreler}")
            
            # AI endpoint fonksiyonlarÄ± mapping
            from .ai_endpoint_functions import ai_endpoint_functions
            
            function_mapping = {
                # Fatura Ä°ÅŸlemleri
                "get_current_bill": ai_endpoint_functions.telekom_get_current_bill,
                "get_past_bills": ai_endpoint_functions.telekom_get_bill_history,
                "pay_bill": ai_endpoint_functions.telekom_pay_bill,
                "get_payment_history": ai_endpoint_functions.telekom_get_payment_history,
                "setup_autopay": ai_endpoint_functions.telekom_setup_autopay,
                
                # Paket Ä°ÅŸlemleri
                "get_current_package": ai_endpoint_functions.telekom_get_current_package,
                "get_available_packages": ai_endpoint_functions.telekom_get_available_packages,
                "change_package": ai_endpoint_functions.telekom_change_package,
                "get_package_details": ai_endpoint_functions.telekom_get_package_details,
                "get_remaining_quotas": ai_endpoint_functions.telekom_get_remaining_quotas,
                
                # MÃ¼ÅŸteri Ä°ÅŸlemleri
                "get_customer_profile": ai_endpoint_functions.telekom_get_customer_profile,
                "update_customer_contact": ai_endpoint_functions.telekom_update_customer_contact,
                "enable_roaming": ai_endpoint_functions.telekom_enable_roaming,
                
                # AÄŸ ve Teknik Ä°ÅŸlemler
                "check_network_status": ai_endpoint_functions.telekom_check_network_status,
                "test_internet_speed": ai_endpoint_functions.telekom_test_internet_speed,
                "suspend_line": ai_endpoint_functions.telekom_suspend_line,
                "reactivate_line": ai_endpoint_functions.telekom_reactivate_line,
                
                # Destek Ä°ÅŸlemleri
                "create_support_ticket": ai_endpoint_functions.telekom_create_support_ticket,
                "close_support_ticket": ai_endpoint_functions.telekom_close_support_ticket,
                "get_support_ticket_status": ai_endpoint_functions.telekom_get_support_ticket_status,
                "get_user_support_tickets": ai_endpoint_functions.telekom_get_user_support_tickets,
                
                # Kimlik DoÄŸrulama
                "auth_register": ai_endpoint_functions.telekom_auth_register,
                "auth_login": ai_endpoint_functions.telekom_auth_login,
            }
            
            if arac_adi not in function_mapping:
                logger.warning(f"Bilinmeyen araÃ§: {arac_adi}")
                return None
            
            # Fonksiyonu Ã§aÄŸÄ±r
            function = function_mapping[arac_adi]
            logger.info(f"AraÃ§ Ã§aÄŸrÄ±sÄ±: {arac_adi} -> {function.__name__}")
            result = await function(**parametreler)
            
            logger.info(f"AI Telekom API yanÄ±tÄ±: {result}")
            logger.info(f"AraÃ§ {arac_adi} sonucu baÅŸarÄ±lÄ±: {result.get('success', False)}")
            return result
            
        except Exception as e:
            logger.error(f"AI Telekom araÃ§ Ã§aÄŸrÄ±sÄ± hatasÄ±: {e}")
            raise
    
    async def sistem_durumu_getir(self) -> Dict[str, Any]:
        """Sistem durumu bilgilerini getir"""
        return {
            "status": "healthy",
            "model_loaded": self._model_loaded,
            "model_name": self.model_name,
            "turkish_nlp": ZEMBEREK_AVAILABLE,
            "langchain_available": LANGCHAIN_AVAILABLE,
            "timestamp": datetime.now().isoformat(),
            "version": "2.2.0",
            "ai_guidance_level": "logical"  # AI'nin mantÄ±klÄ± yÃ¶nlendirme seviyesi
        }

# Global orkestratÃ¶r Ã¶rneÄŸi
ai_orchestrator = YapayZekaOrkestratori() 